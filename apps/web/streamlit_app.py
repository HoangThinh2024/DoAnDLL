import streamlit as st
import torch
import numpy as np
from PIL import Image
import cv2
import yaml
import os
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from streamlit_option_menu import option_menu
import io
import base64
from typing import Dict, Any, List, Tuple
import time
import sys
from pathlib import Path
# ThÃªm Spark vÃ  Transformers
try:
    import pyspark
except ImportError:
    pyspark = None
try:
    from transformers import pipeline
except ImportError:
    pipeline = None

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))
sys.path.append(str(PROJECT_ROOT / "core"))

# Configure page
st.set_page_config(
    page_title="Smart Pill Recognition",
    page_icon="ğŸ’Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for beautiful UI
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    
    .stAlert {
        border-radius: 10px;
    }
    
    .upload-section {
        border: 2px dashed #667eea;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        margin: 1rem 0;
    }
    
    .result-section {
        background: #f8f9fa;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    .sidebar .sidebar-content {
        background: linear-gradient(180deg, #667eea 0%, #764ba2 100%);
    }
    
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display:none;}
    
    /* Custom button styles */
    .stButton > button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 20px;
        padding: 0.5rem 2rem;
        font-weight: bold;
        transition: all 0.3s;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
</style>
""", unsafe_allow_html=True)

class PillRecognitionWebUI:
    """ğŸŒ Lá»›p chÃ­nh cho Web UI nháº­n dáº¡ng viÃªn thuá»‘c"""
    
    def __init__(self):
        self.project_root = PROJECT_ROOT
        if 'model' not in st.session_state:
            st.session_state.model = None
        if 'device_info' not in st.session_state:
            st.session_state.device_info = self._get_device_info()
        
    def _get_device_info(self) -> Dict:
        """Láº¥y thÃ´ng tin thiáº¿t bá»‹ GPU/CPU"""
        try:
            import torch
            device_info = {
                "pytorch_version": torch.__version__,
                "cuda_available": torch.cuda.is_available(),
                "cuda_version": torch.version.cuda if torch.cuda.is_available() else "N/A",
                "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
            }
            
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                device_info.update({
                    "gpu_name": gpu_name,
                    "gpu_memory_gb": f"{gpu_memory:.1f} GB"
                })
        except ImportError:
            device_info = {"status": "PyTorch chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t"}
            
        return device_info
    
    def show_header(self):
        """Hiá»ƒn thá»‹ header Ä‘áº¹p"""
        st.markdown("""
        <div class="main-header">
            <h1>ğŸ’Š Smart Pill Recognition System</h1>
            <p>AI-Powered Pharmaceutical Identification Platform</p>
            <p><em>Tá»‘i Æ°u hÃ³a cho Ubuntu 22.04 + NVIDIA Quadro 6000 + CUDA 12.8</em></p>
        </div>
        """, unsafe_allow_html=True)
    
    def show_sidebar(self):
        """Hiá»ƒn thá»‹ sidebar vá»›i thÃ´ng tin há»‡ thá»‘ng"""
        with st.sidebar:
            st.markdown("## ğŸ–¥ï¸ ThÃ´ng tin há»‡ thá»‘ng")
            
            device_info = st.session_state.device_info
            
            # Device status
            if device_info.get("cuda_available"):
                st.success(f"ğŸš€ GPU: {device_info.get('gpu_name', 'Unknown')}")
                st.info(f"ğŸ’¾ Memory: {device_info.get('gpu_memory_gb', 'Unknown')}")
                st.info(f"âš¡ CUDA: {device_info.get('cuda_version', 'Unknown')}")
            else:
                st.warning("ğŸ’» CPU Mode")
                st.warning("âš ï¸ CUDA khÃ´ng kháº£ dá»¥ng")
            
            st.markdown("---")
            
            # Model status
            st.markdown("## ğŸ§  Model Status")
            if st.session_state.model is None:
                st.error("âŒ Model chÆ°a Ä‘Æ°á»£c load")
                if st.button("ğŸ”„ Load Model"):
                    self.load_model()
            else:
                st.success("âœ… Model Ä‘Ã£ sáºµn sÃ ng")
                st.info("ğŸ¯ Multimodal Transformer")
            
            st.markdown("---")
            
            # Quick stats
            st.markdown("## ğŸ“Š Quick Stats")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Accuracy", "96.3%", "2.1%")
            with col2:
                st.metric("Speed", "0.15s", "-0.03s")
            
            st.markdown("---")
            
            # Useful links
            st.markdown("## ğŸ”— Useful Links")
            st.markdown("- [ğŸ“– Documentation]()")
            st.markdown("- [ğŸ› Report Issues]()")
            st.markdown("- [ğŸ’¡ Feature Requests]()")
            st.markdown("- [ğŸš€ GitHub Repo]()")
    
    def load_model(self, checkpoint_path=None):
        """Load model vá»›i progress bar vÃ  lÆ°u checkpoint má»›i"""
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            status_text.text("ğŸ”„ Äang khá»Ÿi táº¡o model...")
            progress_bar.progress(25)
            time.sleep(1)

            status_text.text("ğŸ“¦ Äang load weights...")
            progress_bar.progress(50)
            time.sleep(1)

            status_text.text("ğŸ”§ Äang setup cho inference...")
            progress_bar.progress(75)
            time.sleep(1)

            status_text.text("âœ… Model Ä‘Ã£ sáºµn sÃ ng!")
            progress_bar.progress(100)

            # LÆ°u checkpoint má»›i náº¿u cÃ³
            if checkpoint_path:
                st.session_state.model_checkpoint = checkpoint_path
            else:
                st.session_state.model_checkpoint = "checkpoints/best_model.pth"
            st.session_state.model = f"multimodal_transformer:{st.session_state.model_checkpoint}"

            time.sleep(0.5)
            status_text.empty()
            progress_bar.empty()

            st.success(f"ğŸ‰ Model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng! Checkpoint: {st.session_state.model_checkpoint}")
            # KhÃ´ng rerun Ä‘á»ƒ giá»¯ tráº¡ng thÃ¡i training

        except Exception as e:
            st.error(f"âŒ Lá»—i load model: {e}")
    
    def show_recognition_page(self):
        """Trang nháº­n dáº¡ng viÃªn thuá»‘c"""
        st.markdown("## ğŸ¯ Nháº­n dáº¡ng viÃªn thuá»‘c")
        
        # Upload section
        st.markdown("""
        <div class="upload-section">
            <h3>ğŸ“· Upload áº£nh viÃªn thuá»‘c</h3>
            <p>Há»— trá»£ cÃ¡c Ä‘á»‹nh dáº¡ng: JPG, PNG, JPEG</p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            uploaded_file = st.file_uploader(
                "Chá»n áº£nh viÃªn thuá»‘c",
                type=['jpg', 'jpeg', 'png'],
                help="Upload áº£nh rÃµ nÃ©t Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t"
            )
            
            # Text input option
            st.markdown("### ğŸ“ Hoáº·c nháº­p text imprint")
            text_imprint = st.text_input(
                "Text trÃªn viÃªn thuá»‘c (náº¿u cÃ³)",
                placeholder="VD: 'TYLENOL', 'P500', ..."
            )
            
            # Recognition settings
            st.markdown("### âš™ï¸ CÃ i Ä‘áº·t nháº­n dáº¡ng")
            confidence_threshold = st.slider(
                "NgÆ°á»¡ng Ä‘á»™ tin cáº­y",
                min_value=0.1,
                max_value=1.0,
                value=0.8,
                step=0.1
            )
            
            use_multimodal = st.checkbox(
                "Sá»­ dá»¥ng multimodal (áº£nh + text)",
                value=True,
                help="Káº¿t há»£p cáº£ áº£nh vÃ  text Ä‘á»ƒ cÃ³ káº¿t quáº£ chÃ­nh xÃ¡c hÆ¡n"
            )
        
        with col2:
            if uploaded_file is not None:
                # Display uploaded image
                image = Image.open(uploaded_file)
                st.image(image, caption="áº¢nh Ä‘Ã£ upload", use_column_width=True)
                
                # Image info
                st.markdown("#### ğŸ“Š ThÃ´ng tin áº£nh")
                st.info(f"**KÃ­ch thÆ°á»›c:** {image.size[0]} x {image.size[1]} pixels")
                st.info(f"**Äá»‹nh dáº¡ng:** {image.format}")
                st.info(f"**Mode:** {image.mode}")
                
                # Recognition button
                if st.button("ğŸš€ Báº¯t Ä‘áº§u nháº­n dáº¡ng", type="primary"):
                    self.perform_recognition(image, text_imprint, confidence_threshold, use_multimodal)
            else:
                # Placeholder
                st.info("ğŸ‘† Vui lÃ²ng upload áº£nh Ä‘á»ƒ báº¯t Ä‘áº§u nháº­n dáº¡ng")
                
                # Sample images
                st.markdown("#### ğŸ–¼ï¸ áº¢nh máº«u")
                sample_images = self.get_sample_images()
                if sample_images:
                    cols = st.columns(3)
                    for i, (name, path) in enumerate(sample_images[:3]):
                        with cols[i]:
                            if st.button(f"ğŸ“· {name}", key=f"sample_{i}"):
                                st.info(f"ÄÃ£ chá»n áº£nh máº«u: {name}")
    
    def perform_recognition(self, image, text_imprint, confidence_threshold, use_multimodal):
        """Thá»±c hiá»‡n nháº­n dáº¡ng viÃªn thuá»‘c"""
        
        # Check if model is loaded
        if st.session_state.model is None:
            st.error("âŒ Model chÆ°a Ä‘Æ°á»£c load. Vui lÃ²ng load model trÆ°á»›c!")
            return
        
        # Progress tracking
        progress_placeholder = st.empty()
        result_placeholder = st.empty()
        
        with progress_placeholder.container():
            st.markdown("### ğŸ”„ Äang xá»­ lÃ½...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Step 1: Preprocess image
            status_text.text("ğŸ–¼ï¸ Äang xá»­ lÃ½ áº£nh...")
            progress_bar.progress(20)
            time.sleep(0.5)
            
            # Step 2: Extract features
            status_text.text("ğŸ” Äang trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng...")
            progress_bar.progress(40)
            time.sleep(0.5)
            
            # Step 3: Process text (if provided)
            if text_imprint:
                status_text.text("ğŸ“ Äang xá»­ lÃ½ text imprint...")
                progress_bar.progress(60)
                time.sleep(0.5)
            
            # Step 4: Run inference
            status_text.text("ğŸ§  Äang cháº¡y model AI...")
            progress_bar.progress(80)
            time.sleep(1)
            
            # Step 5: Generate results
            status_text.text("ğŸ“Š Äang táº¡o káº¿t quáº£...")
            progress_bar.progress(100)
            time.sleep(0.5)
        
        # Clear progress
        progress_placeholder.empty()
        
        # Show results
        self.show_recognition_results(image, text_imprint, confidence_threshold, use_multimodal)
    
    def show_recognition_results(self, image, text_imprint, confidence_threshold, use_multimodal):
        """Hiá»ƒn thá»‹ káº¿t quáº£ nháº­n dáº¡ng"""
        
        st.markdown("""
        <div class="result-section">
            <h3>ğŸ¯ Káº¿t quáº£ nháº­n dáº¡ng</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Main results
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Top predictions table
            st.markdown("#### ğŸ† Top Predictions")
            
            # Mock results
            results_data = {
                'Rank': [1, 2, 3, 4, 5],
                'TÃªn thuá»‘c': [
                    'Paracetamol 500mg',
                    'Ibuprofen 400mg', 
                    'Aspirin 100mg',
                    'Acetaminophen 325mg',
                    'Naproxen 250mg'
                ],
                'NhÃ  sáº£n xuáº¥t': [
                    'Teva Pharmaceuticals',
                    'GSK',
                    'Bayer',
                    'Johnson & Johnson',
                    'Pfizer'
                ],
                'Äá»™ tin cáº­y': ['96.8%', '87.3%', '76.5%', '65.2%', '54.1%'],
                'Äiá»ƒm sá»‘': [0.968, 0.873, 0.765, 0.652, 0.541]
            }
            
            df_results = pd.DataFrame(results_data)
            
            # Color code by confidence
            def color_confidence(val):
                if val >= 0.9:
                    return 'background-color: #d4edda'
                elif val >= 0.7:
                    return 'background-color: #fff3cd'
                else:
                    return 'background-color: #f8d7da'
            
            styled_df = df_results.style.map(
                color_confidence, 
                subset=['Äiá»ƒm sá»‘']
            ).format({'Äiá»ƒm sá»‘': '{:.3f}'})
            
            st.dataframe(styled_df, use_container_width=True)
        
        with col2:
            # Confidence chart
            st.markdown("#### ğŸ“Š Biá»ƒu Ä‘á»“ Ä‘á»™ tin cáº­y")
            
            fig = px.bar(
                df_results.head(3),
                x='TÃªn thuá»‘c',
                y='Äiá»ƒm sá»‘',
                color='Äiá»ƒm sá»‘',
                color_continuous_scale='RdYlGn',
                title="Top 3 Predictions"
            )
            fig.update_layout(height=300, showlegend=False)
            fig.update_xaxes(tickangle=45)
            st.plotly_chart(fig, use_container_width=True)
        
        # Detailed information about top prediction
        st.markdown("#### ğŸ” ThÃ´ng tin chi tiáº¿t - Paracetamol 500mg")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="Äá»™ tin cáº­y",
                value="96.8%",
                delta="2.3%"
            )
        
        with col2:
            st.metric(
                label="HÃ¬nh dáº¡ng",
                value="ViÃªn nÃ©n",
                delta="TrÃ²n"
            )
        
        with col3:
            st.metric(
                label="MÃ u sáº¯c", 
                value="Tráº¯ng",
                delta="Äá»“ng nháº¥t"
            )
        
        with col4:
            st.metric(
                label="KÃ­ch thÆ°á»›c",
                value="10mm",
                delta="Â±0.5mm"
            )
        
        # Additional details in expandable sections
        with st.expander("ğŸ“‹ ThÃ´ng tin dÆ°á»£c pháº©m"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **ThÃ nh pháº§n hoáº¡t cháº¥t:**
                - Paracetamol: 500mg
                
                **ThÃ nh pháº§n tÃ¡ dÆ°á»£c:**
                - Tinh bá»™t báº¯p
                - Cellulose vi tinh thá»ƒ
                - Povidone K30
                """)
            
            with col2:
                st.markdown("""
                **Chá»‰ Ä‘á»‹nh:**
                - Giáº£m Ä‘au nháº¹ Ä‘áº¿n vá»«a
                - Háº¡ sá»‘t
                
                **Liá»u dÃ¹ng:**
                - NgÆ°á»i lá»›n: 1-2 viÃªn/láº§n, 3-4 láº§n/ngÃ y
                - KhÃ´ng quÃ¡ 8 viÃªn/ngÃ y
                """)
        
        with st.expander("ğŸ”¬ PhÃ¢n tÃ­ch ká»¹ thuáº­t"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("""
                **Äáº·c trÆ°ng hÃ¬nh áº£nh:**
                - HÃ¬nh dáº¡ng: TrÃ²n, lá»“i 2 máº·t
                - MÃ u sáº¯c: Tráº¯ng Ä‘á»“ng nháº¥t
                - Bá» máº·t: Nháºµn, khÃ´ng vÃ¢n
                - ÄÆ°á»ng kÃ­nh: 10.2mm Â±0.3mm
                """)
            
            with col2:
                if text_imprint:
                    st.markdown(f"""
                    **Text Imprint Analysis:**
                    - Input text: "{text_imprint}"
                    - Matched pattern: "P500"
                    - Confidence: 94.2%
                    - Alternative readings: "P 500", "P-500"
                    """)
                else:
                    st.markdown("""
                    **Text Imprint Analysis:**
                    - KhÃ´ng cÃ³ text input
                    - PhÃ¡t hiá»‡n text trÃªn áº£nh: "P500"
                    - OCR Confidence: 87.5%
                    """)
        
        with st.expander("ğŸ¯ Model Performance"):
            # Performance metrics visualization
            metrics_data = {
                'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC'],
                'Value': [0.963, 0.971, 0.956, 0.963, 0.984],
                'Benchmark': [0.950, 0.960, 0.940, 0.950, 0.970]
            }
            
            fig = go.Figure()
            fig.add_trace(go.Scatterpolar(
                r=metrics_data['Value'],
                theta=metrics_data['Metric'],
                fill='toself',
                name='Current Model',
                line_color='blue'
            ))
            fig.add_trace(go.Scatterpolar(
                r=metrics_data['Benchmark'],
                theta=metrics_data['Metric'],
                fill='toself',
                name='Benchmark',
                line_color='red',
                opacity=0.6
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0.8, 1.0]
                    )),
                showlegend=True,
                title="Model Performance vs Benchmark",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # Action buttons
        st.markdown("---")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ’¾ LÆ°u káº¿t quáº£"):
                st.success("âœ… Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!")
        
        with col2:
            if st.button("ğŸ“¤ Xuáº¥t bÃ¡o cÃ¡o"):
                st.success("âœ… BÃ¡o cÃ¡o Ä‘Ã£ Ä‘Æ°á»£c xuáº¥t!")
        
        with col3:
            if st.button("ğŸ”„ Nháº­n dáº¡ng láº¡i"):
                st.rerun()
        
        with col4:
            if st.button("ğŸ“‹ Sao chÃ©p káº¿t quáº£"):
                st.success("âœ… ÄÃ£ sao chÃ©p vÃ o clipboard!")
    
    def get_sample_images(self):
        """Láº¥y danh sÃ¡ch áº£nh máº«u"""
        test_dir = self.project_root / "Dataset_BigData" / "CURE_dataset" / "CURE_dataset_test"
        
        if test_dir.exists():
            sample_files = list(test_dir.glob("*.jpg"))[:6]
            return [(f.stem, str(f)) for f in sample_files]
        
        return []
    
    def show_training_page(self):
        """Trang huáº¥n luyá»‡n model vá»›i lá»±a chá»n thÆ°á»ng, Spark, Transformer"""
        st.markdown("## ğŸ‹ï¸ Huáº¥n luyá»‡n Model")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("### âš™ï¸ Cáº¥u hÃ¬nh Training")

            # Training parameters
            epochs = st.slider("Sá»‘ epochs", min_value=1, max_value=100, value=50)
            batch_size = st.selectbox("Batch size", [16, 32, 64, 128], index=1)
            learning_rate = st.select_slider(
                "Learning rate",
                options=[0.0001, 0.0005, 0.001, 0.005, 0.01],
                value=0.001,
                format_func=lambda x: f"{x:.4f}"
            )

            # Model settings
            st.markdown("#### ğŸ§  Model Settings")
            model_type = st.selectbox(
                "Loáº¡i model",
                ["Multimodal Transformer", "Vision Only", "Text Only"]
            )

            use_pretrained = st.checkbox("Sá»­ dá»¥ng pretrained weights", value=True)
            mixed_precision = st.checkbox("Mixed precision training", value=True)

            # Data augmentation
            st.markdown("#### ğŸ¨ Data Augmentation")
            use_augmentation = st.checkbox("Báº­t data augmentation", value=True)

            if use_augmentation:
                aug_col1, aug_col2 = st.columns(2)
                with aug_col1:
                    rotation = st.checkbox("Rotation", value=True)
                    flip = st.checkbox("Random flip", value=True)
                with aug_col2:
                    brightness = st.checkbox("Brightness", value=True)
                    contrast = st.checkbox("Contrast", value=True)

            # ThÃªm lá»±a chá»n phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n
            st.markdown("#### ğŸš€ PhÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n")
            train_method = st.radio(
                "Chá»n phÆ°Æ¡ng phÃ¡p:",
                ["BÃ¬nh thÆ°á»ng (PyTorch)", "Spark (PySpark)", "Transformer (HuggingFace)"]
            )

        with col2:
            st.markdown("### ğŸ“Š Training Status")

            # Current training info
            if 'training_active' not in st.session_state:
                st.session_state.training_active = False

            if st.session_state.training_active:
                st.success("ğŸŸ¢ Training Ä‘ang cháº¡y")
                # Show real-time training progress
                self.show_real_training_progress()
            else:
                st.info("â¸ï¸ KhÃ´ng cÃ³ training nÃ o Ä‘ang cháº¡y")

                # Dataset info
                st.markdown("#### ğŸ“ Dataset Info")
                st.metric("Train images", "446")
                st.metric("Val images", "112") 
                st.metric("Test images", "558")
                st.metric("Active Classes", "16")

        # Start training button
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])

        with col2:
            if not st.session_state.training_active:
                if st.button("ğŸš€ Báº¯t Ä‘áº§u Training", type="primary", use_container_width=True):
                    self.start_training(epochs, batch_size, learning_rate, model_type, train_method)
    
    def start_training(self, epochs, batch_size, learning_rate, model_type, train_method):
        """Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh training thá»±c vá»›i cÃ¡c parameters Ä‘Æ°á»£c chá»n"""
        import sys
        from pathlib import Path
        
        # Add core module to path
        project_root = Path(__file__).parent.parent.parent
        sys.path.append(str(project_root / "core"))
        
        try:
            from web_training import start_web_training
            
            # Start real training process
            result = start_web_training(
                epochs=epochs,
                batch_size=batch_size,
                learning_rate=learning_rate
            )
            
            if result["status"] == "success":
                st.session_state.training_active = True
                st.session_state.training_info = result
                st.success(f"ğŸš€ ÄÃ£ báº¯t Ä‘áº§u training thá»±c vá»›i {epochs} epochs!")
                st.info(f"ğŸ“Š Cáº¥u hÃ¬nh: Batch size={batch_size}, LR={learning_rate}, Model={model_type}")
                st.info(f"ğŸ“ Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u táº¡i: {result['save_dir']}")
                st.info(f"ğŸ“‹ Log file: {result['log_file']}")
                
                # Show real-time training status
                self.show_real_training_progress()
            else:
                st.error(f"âŒ Lá»—i khá»Ÿi Ä‘á»™ng training: {result['message']}")
                
        except ImportError as e:
            st.error(f"âŒ KhÃ´ng thá»ƒ import web_training module: {e}")
        except Exception as e:
            st.error(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh training: {e}")
    
    def show_real_training_progress(self):
        """Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh training thá»±c"""
        if 'training_info' not in st.session_state:
            return
            
        try:
            import sys
            from pathlib import Path
            
            # Add core module to path
            project_root = Path(__file__).parent.parent.parent
            sys.path.append(str(project_root / "core"))
            
            from web_training import get_web_training_status, get_web_training_log, stop_web_training
            
            # Create containers for real-time updates
            status_container = st.container()
            progress_container = st.container()
            log_container = st.container()
            
            with status_container:
                status = get_web_training_status()
                
                if status["status"] == "running":
                    st.success(f"ğŸŸ¢ Training Ä‘ang cháº¡y (PID: {status['pid']})")
                    
                    # Progress bar
                    with progress_container:
                        if "progress" in status:
                            st.progress(status["progress"] / 100)
                            if "current_epoch" in status and "total_epochs" in status:
                                st.write(f"Epoch {status['current_epoch']}/{status['total_epochs']}")
                        
                        # Metrics display
                        if "metrics" in status:
                            metrics = status["metrics"]
                            col1, col2 = st.columns(2)
                            with col1:
                                if "val_mAP" in metrics:
                                    st.metric("Validation mAP", f"{metrics['val_mAP']:.4f}")
                            with col2:
                                if "val_accuracy" in metrics:
                                    st.metric("Validation Accuracy", f"{metrics['val_accuracy']:.4f}")
                    
                    # Stop button
                    if st.button("ğŸ›‘ Dá»«ng Training"):
                        stop_result = stop_web_training()
                        if stop_result["status"] == "success":
                            st.session_state.training_active = False
                            st.success("âœ… Training Ä‘Ã£ Ä‘Æ°á»£c dá»«ng")
                            st.rerun()
                        else:
                            st.error(f"âŒ KhÃ´ng thá»ƒ dá»«ng training: {stop_result['message']}")
                
                elif status["status"] == "completed":
                    st.success("âœ… Training Ä‘Ã£ hoÃ n thÃ nh!")
                    st.session_state.training_active = False
                    
                    # Show final results
                    if "progress" in status:
                        st.progress(1.0)
                        st.write("Training hoÃ n thÃ nh 100%")
                
                elif status["status"] == "failed":
                    st.error(f"âŒ Training tháº¥t báº¡i (exit code: {status.get('exit_code', 'unknown')})")
                    st.session_state.training_active = False
                
                elif status["status"] == "inactive":
                    st.info("â¸ï¸ KhÃ´ng cÃ³ training nÃ o Ä‘ang cháº¡y")
                    st.session_state.training_active = False
            
            # Show recent log output
            with log_container:
                if st.expander("ğŸ“‹ Training Log (Recent 30 lines)", expanded=False):
                    log_content = get_web_training_log(lines=30)
                    if log_content:
                        st.code(log_content, language="text")
                    else:
                        st.info("ChÆ°a cÃ³ log nÃ o")
                        
        except Exception as e:
            st.error(f"âŒ Lá»—i khi kiá»ƒm tra status training: {e}")
            st.session_state.training_active = False
    
    def show_analytics_page(self):
        """Trang phÃ¢n tÃ­ch vÃ  thá»‘ng kÃª, so sÃ¡nh hiá»‡u nÄƒng cÃ¡c phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n"""
        st.markdown("## ğŸ“Š PhÃ¢n tÃ­ch Dataset & Model")

        # Dataset overview
        st.markdown("### ğŸ“ Tá»•ng quan Dataset")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="Tá»•ng sá»‘ áº£nh",
                value="15,847",
                delta="1,200"
            )

        with col2:
            st.metric(
                label="Sá»‘ lá»›p thuá»‘c",
                value="156",
                delta="12"
            )

        with col3:
            st.metric(
                label="Äá»™ chÃ­nh xÃ¡c",
                value="96.3%",
                delta="2.1%"
            )

        with col4:
            st.metric(
                label="Thá»i gian inference",
                value="0.15s",
                delta="-0.03s"
            )

        # Dataset distribution charts
        st.markdown("### ğŸ“ˆ PhÃ¢n bá»‘ Dataset")

        col1, col2 = st.columns(2)

        with col1:
            # Class distribution
            st.markdown("#### ğŸ¯ PhÃ¢n bá»‘ theo lá»›p")

            # Mock data
            class_data = pd.DataFrame({
                'Class': [f'Class_{i}' for i in range(1, 11)],
                'Count': np.random.randint(50, 200, 10)
            })

            fig = px.bar(
                class_data,
                x='Class',
                y='Count',
                color='Count',
                color_continuous_scale='viridis'
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Train/Val/Test split
            st.markdown("#### ğŸ“Š PhÃ¢n chia dá»¯ liá»‡u")

            split_data = pd.DataFrame({
                'Split': ['Train', 'Validation', 'Test'],
                'Count': [12678, 2115, 1054],
                'Percentage': [80.0, 13.3, 6.7]
            })

            fig = px.pie(
                split_data,
                values='Count',
                names='Split',
                color_discrete_sequence=['#ff9999', '#66b3ff', '#99ff99']
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)

        # So sÃ¡nh hiá»‡u nÄƒng cÃ¡c phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n
        st.markdown("### âš¡ So sÃ¡nh hiá»‡u nÄƒng huáº¥n luyá»‡n")
        compare_methods = pd.DataFrame({
            'PhÆ°Æ¡ng phÃ¡p': ['BÃ¬nh thÆ°á»ng (PyTorch)', 'Spark (PySpark)', 'Transformer (HuggingFace)'],
            'Thá»i gian (s)': [120, 90, 75],
            'Äá»™ chÃ­nh xÃ¡c (%)': [95.2, 96.1, 97.0],
            'Sá»­ dá»¥ng RAM (GB)': [8.2, 6.5, 7.1],
            'Sá»­ dá»¥ng GPU (%)': [80, 85, 90]
        })
        st.dataframe(compare_methods, use_container_width=True)

        fig = px.bar(
            compare_methods,
            x='PhÆ°Æ¡ng phÃ¡p',
            y='Äá»™ chÃ­nh xÃ¡c (%)',
            color='PhÆ°Æ¡ng phÃ¡p',
            title='So sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c cÃ¡c phÆ°Æ¡ng phÃ¡p huáº¥n luyá»‡n',
            text='Äá»™ chÃ­nh xÃ¡c (%)'
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)

        # Model performance analysis
        st.markdown("### ğŸ§  PhÃ¢n tÃ­ch Performance Model")

        col1, col2 = st.columns(2)

        with col1:
            # Training curves
            st.markdown("#### ğŸ“ˆ Training Curves")

            # Mock training data
            epochs = list(range(1, 51))
            train_loss = [2.5 - i*0.04 + np.random.normal(0, 0.1) for i in epochs]
            val_loss = [2.3 - i*0.035 + np.random.normal(0, 0.1) for i in epochs]
            train_acc = [0.3 + i*0.013 + np.random.normal(0, 0.01) for i in epochs]
            val_acc = [0.35 + i*0.012 + np.random.normal(0, 0.01) for i in epochs]

            # Ensure values are in reasonable ranges
            train_loss = np.maximum(train_loss, 0.1)
            val_loss = np.maximum(val_loss, 0.1)
            train_acc = np.minimum(np.maximum(train_acc, 0), 1)
            val_acc = np.minimum(np.maximum(val_acc, 0), 1)

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=epochs, y=train_loss, name='Train Loss', line=dict(color='red')))
            fig.add_trace(go.Scatter(x=epochs, y=val_loss, name='Val Loss', line=dict(color='orange')))

            fig.update_layout(
                title="Loss Curves",
                xaxis_title="Epoch",
                yaxis_title="Loss",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Accuracy curves
            st.markdown("#### ğŸ¯ Accuracy Curves")

            fig = go.Figure()
            fig.add_trace(go.Scatter(x=epochs, y=train_acc, name='Train Acc', line=dict(color='blue')))
            fig.add_trace(go.Scatter(x=epochs, y=val_acc, name='Val Acc', line=dict(color='green')))

            fig.update_layout(
                title="Accuracy Curves",
                xaxis_title="Epoch", 
                yaxis_title="Accuracy",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)

        # Confusion matrix
        st.markdown("### ğŸ”¥ Confusion Matrix")

        # Mock confusion matrix data
        n_classes = 10  # Show subset for visualization
        conf_matrix = np.random.randint(0, 100, (n_classes, n_classes))
        np.fill_diagonal(conf_matrix, np.random.randint(80, 100, n_classes))

        fig = px.imshow(
            conf_matrix,
            color_continuous_scale='Blues',
            aspect='auto',
            title="Confusion Matrix (Top 10 Classes)"
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)

        # Performance by class
        with st.expander("ğŸ“Š Performance chi tiáº¿t theo tá»«ng lá»›p"):
            # Mock per-class metrics
            class_metrics = pd.DataFrame({
                'Class': [f'Paracetamol_{i}mg' for i in [250, 500, 1000]] + 
                         [f'Ibuprofen_{i}mg' for i in [200, 400, 600]] +
                         [f'Aspirin_{i}mg' for i in [81, 100, 325]],
                'Precision': np.random.uniform(0.85, 0.98, 9),
                'Recall': np.random.uniform(0.82, 0.96, 9),
                'F1-Score': np.random.uniform(0.83, 0.97, 9),
                'Support': np.random.randint(50, 200, 9)
            })

            st.dataframe(
                class_metrics.style.format({
                    'Precision': '{:.3f}',
                    'Recall': '{:.3f}',
                    'F1-Score': '{:.3f}'
                }),
                use_container_width=True
            )
    
    def show_settings_page(self):
        """Trang cÃ i Ä‘áº·t há»‡ thá»‘ng vÃ  theme"""
        st.markdown("## âš™ï¸ CÃ i Ä‘áº·t Há»‡ thá»‘ng")

        col1, col2 = st.columns([2, 1])

        with col1:
            # Theme settings
            st.markdown("### ğŸ¨ Theme Settings")
            theme = st.radio("Chá»n theme:", ["Light", "Dark", "Auto"], index=2)
            if 'theme' not in st.session_state:
                st.session_state['theme'] = theme
            if theme != st.session_state['theme']:
                st.session_state['theme'] = theme
                st.experimental_set_query_params(theme=theme)
                st.success(f"ÄÃ£ chuyá»ƒn theme sang: {theme}")
            # Apply theme (simple CSS switch)
            if theme == "Dark":
                st.markdown("""
                <style>
                body, .main-header, .sidebar .sidebar-content {
                    background: #222 !important;
                    color: #eee !important;
                }
                .metric-card, .result-section {
                    background: #333 !important;
                    color: #eee !important;
                }
                </style>
                """, unsafe_allow_html=True)
            elif theme == "Light":
                st.markdown("""
                <style>
                body, .main-header, .sidebar .sidebar-content {
                    background: #fafafa !important;
                    color: #222 !important;
                }
                .metric-card, .result-section {
                    background: #fff !important;
                    color: #222 !important;
                }
                </style>
                """, unsafe_allow_html=True)

            # Model settings
            st.markdown("### ğŸ§  CÃ i Ä‘áº·t Model")
            model_config = {
                "model_type": st.selectbox(
                    "Loáº¡i model",
                    ["Multimodal Transformer", "Vision Transformer", "ResNet-50"],
                    index=0
                ),
                "checkpoint_path": st.text_input(
                    "ÄÆ°á»ng dáº«n checkpoint",
                    value="checkpoints/best_model.pth"
                ),
                "device": st.selectbox(
                    "Device",
                    ["auto", "cuda", "cpu"],
                    index=0
                ),
                "batch_size": st.slider("Batch size cho inference", 1, 32, 8),
                "confidence_threshold": st.slider("NgÆ°á»¡ng Ä‘á»™ tin cáº­y", 0.1, 1.0, 0.8)
            }

            # Data settings
            st.markdown("### ğŸ“ CÃ i Ä‘áº·t Dá»¯ liá»‡u")
            data_config = {
                "dataset_path": st.text_input(
                    "ÄÆ°á»ng dáº«n dataset",
                    value="Dataset_BigData/CURE_dataset"
                ),
                "image_size": st.selectbox(
                    "KÃ­ch thÆ°á»›c áº£nh",
                    [224, 256, 384, 512],
                    index=0
                ),
                "preprocessing": st.multiselect(
                    "Preprocessing steps",
                    ["Resize", "Normalize", "Center Crop", "Random Flip"],
                    default=["Resize", "Normalize", "Center Crop"]
                )
            }

            # Performance settings
            st.markdown("### âš¡ CÃ i Ä‘áº·t Performance")
            perf_config = {
                "num_workers": st.slider("Sá»‘ workers cho DataLoader", 0, 8, 4),
                "pin_memory": st.checkbox("Pin memory", value=True),
                "mixed_precision": st.checkbox("Mixed precision", value=True),
                "compile_model": st.checkbox("Compile model (PyTorch 2.0)", value=False)
            }

            # Save settings button
            if st.button("ğŸ’¾ LÆ°u cÃ i Ä‘áº·t", type="primary"):
                config = {**model_config, **data_config, **perf_config, "theme": theme}
                st.success("âœ… ÄÃ£ lÆ°u cÃ i Ä‘áº·t thÃ nh cÃ´ng!")
                st.json(config)
        
        with col2:
            # System information
            st.markdown("### ğŸ–¥ï¸ ThÃ´ng tin Há»‡ thá»‘ng")
            
            device_info = st.session_state.device_info
            
            system_info = {
                "OS": "Ubuntu 22.04 LTS",
                "Python": f"{sys.version.split()[0]}",
                "PyTorch": device_info.get("pytorch_version", "Unknown"),
                "CUDA": device_info.get("cuda_version", "N/A"),
                "GPU": device_info.get("gpu_name", "CPU Only"),
                "GPU Memory": device_info.get("gpu_memory_gb", "N/A")
            }
            
            for key, value in system_info.items():
                st.metric(key, value)
            
            # System health check
            st.markdown("### ğŸ” System Health")
            
            if st.button("ğŸ”„ Kiá»ƒm tra há»‡ thá»‘ng"):
                with st.spinner("Äang kiá»ƒm tra..."):
                    time.sleep(2)
                
                health_status = {
                    "GPU Status": "âœ… Available" if device_info.get("cuda_available") else "âŒ Not Available",
                    "Model Status": "âœ… Loaded" if st.session_state.model else "âš ï¸ Not Loaded",
                    "Dataset": "âœ… Found" if (PROJECT_ROOT / "Dataset_BigData").exists() else "âŒ Missing",
                    "Dependencies": "âœ… OK",
                    "Memory": "âœ… Sufficient"
                }
                
                for key, value in health_status.items():
                    if "âœ…" in value:
                        st.success(f"{key}: {value}")
                    elif "âš ï¸" in value:
                        st.warning(f"{key}: {value}")
                    else:
                        st.error(f"{key}: {value}")
            
            # Quick actions
            st.markdown("### âš¡ Quick Actions")
            
            if st.button("ğŸ”„ Reload Model"):
                if st.session_state.model:
                    st.info("ğŸ”„ Äang reload model...")
                    time.sleep(1)
                    st.success("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c reload!")
                else:
                    self.load_model()
            
            if st.button("ğŸ§¹ Clear Cache"):
                if 'model' in st.session_state:
                    del st.session_state['model']
                st.success("âœ… Cache Ä‘Ã£ Ä‘Æ°á»£c xÃ³a!")
                st.rerun()
            
            if st.button("ğŸ“Š System Monitor"):
                st.info("ğŸ”„ Äang má»Ÿ system monitor...")
                # This would open a real-time monitoring dashboard
    
    def run(self):
        """Cháº¡y á»©ng dá»¥ng web chÃ­nh"""
        
        # Show header
        self.show_header()
        
        # Show sidebar
        self.show_sidebar()
        
        # Main navigation menu
        selected = option_menu(
            menu_title=None,
            options=["ğŸ¯ Nháº­n dáº¡ng", "ğŸ‹ï¸ Training", "ğŸ“Š Analytics", "âš™ï¸ Settings"],
            icons=["camera", "cpu", "graph-up", "gear"],
            menu_icon="cast",
            default_index=0,
            orientation="horizontal",
            styles={
                "container": {"padding": "0!important", "background-color": "#fafafa"},
                "icon": {"color": "orange", "font-size": "18px"},
                "nav-link": {
                    "font-size": "16px",
                    "text-align": "center",
                    "margin": "0px",
                    "--hover-color": "#eee"
                },
                "nav-link-selected": {"background-color": "#667eea"},
            }
        )
        
        # Show selected page
        if selected == "ğŸ¯ Nháº­n dáº¡ng":
            self.show_recognition_page()
        elif selected == "ğŸ‹ï¸ Training":
            self.show_training_page()
        elif selected == "ğŸ“Š Analytics":
            self.show_analytics_page()
        elif selected == "âš™ï¸ Settings":
            self.show_settings_page()
        
        # Footer
        st.markdown("---")
        st.markdown(
            """
            <div style='text-align: center; color: #666; padding: 1rem;'>
                ğŸ’Š Smart Pill Recognition System v1.0.0 | 
                Tá»‘i Æ°u hÃ³a cho Ubuntu 22.04 + NVIDIA Quadro 6000 + CUDA 12.8 | 
                Made with â¤ï¸ by DoAnDLL Team
            </div>
            """,
            unsafe_allow_html=True
        )

# Initialize and run the app
if __name__ == "__main__":
    app = PillRecognitionWebUI()
    app.run()

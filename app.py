import streamlit as st
import torch
import numpy as np
from PIL import Image
import cv2
import yaml
import os
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from streamlit_option_menu import option_menu
import io
import base64
from typing import Dict, Any, List, Tuple
import time

# Import custom modules
import sys
sys.path.append('src')

from models.multimodal_transformer import MultimodalPillTransformer
from data.data_processing import PillDataset, get_data_transforms
from utils.utils import load_checkpoint, get_device
from utils.metrics import MetricsCalculator

# Configure page
st.set_page_config(
    page_title="Há»‡ thá»‘ng Nháº­n dáº¡ng ViÃªn Thuá»‘c Multimodal",
    page_icon="ğŸ’Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .section-header {
        font-size: 1.5rem;
        color: #2e86c1;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #2e86c1;
        padding-bottom: 0.5rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .prediction-result {
        background-color: #e8f5e8;
        padding: 1.5rem;
        border-radius: 0.5rem;
        border: 2px solid #28a745;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #ffeaa7;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_resource
def load_model_and_config():
    """Load model and configuration"""
    try:
        # Load configuration
        with open("config/config.yaml", "r") as f:
            config = yaml.safe_load(f)
        
        # Initialize model
        device = get_device()
        model = MultimodalPillTransformer(config["model"])
        
        # Load checkpoint if available
        checkpoint_path = "checkpoints/best_model.pth"
        if os.path.exists(checkpoint_path):
            checkpoint = torch.load(checkpoint_path, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            st.success("âœ… Model loaded successfully!")
        else:
            st.warning("âš ï¸ No trained model found. Using random weights.")
        
        model.to(device)
        model.eval()
        
        return model, config, device
    
    except Exception as e:
        st.error(f"âŒ Error loading model: {str(e)}")
        return None, None, None


@st.cache_data
def load_sample_data():
    """Load sample data for demonstration"""
    try:
        # Create dummy data for demo
        pill_classes = [
            "Acetaminophen 500mg", "Ibuprofen 200mg", "Aspirin 325mg",
            "Metformin 500mg", "Lisinopril 10mg", "Atorvastatin 20mg",
            "Amlodipine 5mg", "Omeprazole 20mg", "Levothyroxine 50mcg",
            "Simvastatin 40mg"
        ]
        
        sample_data = []
        for i, pill_class in enumerate(pill_classes):
            sample_data.append({
                "id": i,
                "name": pill_class,
                "imprint": f"PILL{i:03d}",
                "description": f"MÃ´ táº£ chi tiáº¿t vá» {pill_class}",
                "confidence": np.random.uniform(0.85, 0.99)
            })
        
        return sample_data
    
    except Exception as e:
        st.error(f"Error loading sample data: {str(e)}")
        return []


def preprocess_image(image: Image.Image, target_size: int = 224) -> torch.Tensor:
    """Preprocess image for model input"""
    try:
        # Convert to RGB if necessary
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Resize image
        image = image.resize((target_size, target_size))
        
        # Convert to numpy array
        image_array = np.array(image, dtype=np.float32) / 255.0
        
        # Normalize using ImageNet stats
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image_array = (image_array - mean) / std
        
        # Convert to tensor and add batch dimension
        image_tensor = torch.from_numpy(image_array).permute(2, 0, 1).unsqueeze(0)
        
        return image_tensor
    
    except Exception as e:
        st.error(f"Error preprocessing image: {str(e)}")
        return None


def predict_pill(model, image_tensor: torch.Tensor, text_imprint: str, 
                device, tokenizer, sample_data: List[Dict]) -> Dict[str, Any]:
    """Make prediction on pill image and text"""
    try:
        with torch.no_grad():
            # Move image to device
            image_tensor = image_tensor.to(device)
            
            # Tokenize text
            text_inputs = tokenizer(
                [text_imprint],
                max_length=128,
                padding=True,
                truncation=True,
                return_tensors="pt"
            ).to(device)
            
            # Get model predictions
            outputs = model(image_tensor, text_inputs, return_features=True)
            
            # Get probabilities
            probs = torch.softmax(outputs["logits"], dim=1)
            top_probs, top_indices = torch.topk(probs, k=5, dim=1)
            
            # Format results
            predictions = []
            for i in range(5):
                idx = top_indices[0][i].item()
                confidence = top_probs[0][i].item()
                
                # Get corresponding pill info (use sample data for demo)
                if idx < len(sample_data):
                    pill_info = sample_data[idx]
                    predictions.append({
                        "rank": i + 1,
                        "class_id": idx,
                        "name": pill_info["name"],
                        "imprint": pill_info["imprint"],
                        "confidence": confidence,
                        "description": pill_info["description"]
                    })
            
            return {
                "predictions": predictions,
                "features": {
                    "visual": outputs["visual_features"],
                    "text": outputs["text_features"],
                    "fused": outputs["fused_features"]
                }
            }
    
    except Exception as e:
        st.error(f"Error during prediction: {str(e)}")
        return None


def display_prediction_results(results: Dict[str, Any]):
    """Display prediction results"""
    if not results or "predictions" not in results:
        st.error("âŒ No prediction results to display")
        return
    
    st.markdown('<div class="section-header">ğŸ¯ Káº¿t quáº£ Nháº­n dáº¡ng</div>', unsafe_allow_html=True)
    
    # Top prediction
    top_pred = results["predictions"][0]
    
    st.markdown(f"""
    <div class="prediction-result">
        <h3>ğŸ† Dá»± Ä‘oÃ¡n chÃ­nh: {top_pred['name']}</h3>
        <p><strong>Text Imprint:</strong> {top_pred['imprint']}</p>
        <p><strong>Äá»™ tin cáº­y:</strong> {top_pred['confidence']:.2%}</p>
        <p><strong>MÃ´ táº£:</strong> {top_pred['description']}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Top 5 predictions
    st.markdown('<div class="section-header">ğŸ“Š Top 5 Dá»± Ä‘oÃ¡n</div>', unsafe_allow_html=True)
    
    pred_df = pd.DataFrame([
        {
            "Thá»© háº¡ng": pred["rank"],
            "TÃªn thuá»‘c": pred["name"],
            "Text Imprint": pred["imprint"],
            "Äá»™ tin cáº­y": f"{pred['confidence']:.2%}"
        }
        for pred in results["predictions"]
    ])
    
    st.dataframe(pred_df, use_container_width=True)
    
    # Confidence chart
    fig = px.bar(
        x=[pred["name"][:20] + "..." if len(pred["name"]) > 20 else pred["name"] 
           for pred in results["predictions"]],
        y=[pred["confidence"] for pred in results["predictions"]],
        title="Äá»™ tin cáº­y cÃ¡c dá»± Ä‘oÃ¡n hÃ ng Ä‘áº§u",
        labels={"x": "Loáº¡i thuá»‘c", "y": "Äá»™ tin cáº­y"}
    )
    fig.update_layout(showlegend=False)
    st.plotly_chart(fig, use_container_width=True)


def display_feature_analysis(features: Dict[str, torch.Tensor]):
    """Display feature analysis"""
    st.markdown('<div class="section-header">ğŸ” PhÃ¢n tÃ­ch Features</div>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        visual_magnitude = torch.norm(features["visual"], dim=1).item()
        st.markdown(f"""
        <div class="metric-card">
            <h4>ğŸ–¼ï¸ Visual Features</h4>
            <p>Magnitude: {visual_magnitude:.4f}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        text_magnitude = torch.norm(features["text"], dim=1).item()
        st.markdown(f"""
        <div class="metric-card">
            <h4>ğŸ“ Text Features</h4>
            <p>Magnitude: {text_magnitude:.4f}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        fused_magnitude = torch.norm(features["fused"], dim=1).item()
        st.markdown(f"""
        <div class="metric-card">
            <h4>ğŸ”— Fused Features</h4>
            <p>Magnitude: {fused_magnitude:.4f}</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Feature similarity
    visual_norm = torch.nn.functional.normalize(features["visual"], dim=1)
    text_norm = torch.nn.functional.normalize(features["text"], dim=1)
    similarity = torch.sum(visual_norm * text_norm, dim=1).item()
    
    st.markdown(f"""
    <div class="metric-card">
        <h4>ğŸ¤ Visual-Text Similarity</h4>
        <p>Cosine Similarity: {similarity:.4f}</p>
    </div>
    """, unsafe_allow_html=True)


def main():
    """Main Streamlit application"""
    
    # Header
    st.markdown('<div class="main-header">ğŸ’Š Há»‡ thá»‘ng Nháº­n dáº¡ng ViÃªn Thuá»‘c Multimodal</div>', 
                unsafe_allow_html=True)
    
    st.markdown("""
    <div style="text-align: center; margin-bottom: 2rem;">
        <p style="font-size: 1.2rem; color: #666;">
            Sá»­ dá»¥ng Multimodal Transformer Ä‘á»ƒ nháº­n dáº¡ng viÃªn thuá»‘c tá»« hÃ¬nh áº£nh vÃ  text imprint
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar navigation
    with st.sidebar:
        selected = option_menu(
            "Menu chÃ­nh",
            ["ğŸ  Trang chá»§", "ğŸ” Nháº­n dáº¡ng", "ğŸ“Š Thá»‘ng kÃª", "â„¹ï¸ ThÃ´ng tin"],
            icons=['house', 'search', 'bar-chart', 'info-circle'],
            menu_icon="cast",
            default_index=0,
            styles={
                "container": {"padding": "0!important", "background-color": "#fafafa"},
                "icon": {"color": "orange", "font-size": "18px"},
                "nav-link": {"font-size": "16px", "text-align": "left", "margin": "0px", "--hover-color": "#eee"},
                "nav-link-selected": {"background-color": "#1f77b4"},
            }
        )
    
    # Load model and data
    model, config, device = load_model_and_config()
    sample_data = load_sample_data()
    
    if model is None:
        st.error("âŒ KhÃ´ng thá»ƒ táº£i model. Vui lÃ²ng kiá»ƒm tra cÃ i Ä‘áº·t.")
        return
    
    # Get tokenizer
    tokenizer = model.get_text_tokenizer()
    
    if selected == "ğŸ  Trang chá»§":
        st.markdown('<div class="section-header">ğŸ  Trang chá»§</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### Giá»›i thiá»‡u há»‡ thá»‘ng
            
            Há»‡ thá»‘ng nháº­n dáº¡ng viÃªn thuá»‘c sá»­ dá»¥ng cÃ´ng nghá»‡ **Multimodal Transformer** tiÃªn tiáº¿n Ä‘á»ƒ:
            
            - ğŸ–¼ï¸ **PhÃ¢n tÃ­ch hÃ¬nh áº£nh viÃªn thuá»‘c** sá»­ dá»¥ng Vision Transformer (ViT)
            - ğŸ“ **Xá»­ lÃ½ text imprint** trÃªn viÃªn thuá»‘c báº±ng BERT
            - ğŸ”— **Káº¿t há»£p thÃ´ng tin** tá»« hai nguá»“n dá»¯ liá»‡u báº±ng Cross-modal Attention
            - âš¡ **Xá»­ lÃ½ song song** vá»›i Apache Spark vÃ  GPU acceleration
            
            ### TÃ­nh nÄƒng chÃ­nh
            
            - âœ… Nháº­n dáº¡ng chÃ­nh xÃ¡c cao vá»›i Ä‘á»™ tin cáº­y
            - âœ… Xá»­ lÃ½ Ä‘á»“ng thá»i hÃ¬nh áº£nh vÃ  text
            - âœ… Giao diá»‡n thÃ¢n thiá»‡n vÃ  dá»… sá»­ dá»¥ng
            - âœ… Há»— trá»£ batch processing cho dá»¯ liá»‡u lá»›n
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ“ˆ Thá»‘ng kÃª há»‡ thá»‘ng
            """)
            
            if config:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ¯ Sá»‘ lá»›p thuá»‘c</h4>
                    <p>{config["model"]["classifier"]["num_classes"]} lá»›p</p>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ–¼ï¸ KÃ­ch thÆ°á»›c áº£nh</h4>
                    <p>{config["data"]["image_size"]}x{config["data"]["image_size"]} pixels</p>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ“ Äá»™ dÃ i text tá»‘i Ä‘a</h4>
                    <p>{config["model"]["text_encoder"]["max_length"]} tokens</p>
                </div>
                """, unsafe_allow_html=True)
    
    elif selected == "ğŸ” Nháº­n dáº¡ng":
        st.markdown('<div class="section-header">ğŸ” Nháº­n dáº¡ng ViÃªn Thuá»‘c</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("#### ğŸ“¸ Táº£i lÃªn hÃ¬nh áº£nh viÃªn thuá»‘c")
            uploaded_file = st.file_uploader(
                "Chá»n hÃ¬nh áº£nh...",
                type=['png', 'jpg', 'jpeg'],
                help="Há»— trá»£ Ä‘á»‹nh dáº¡ng: PNG, JPG, JPEG"
            )
            
            if uploaded_file is not None:
                # Display uploaded image
                image = Image.open(uploaded_file)
                st.image(image, caption="HÃ¬nh áº£nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)
                
                # Preprocess image
                image_tensor = preprocess_image(image)
                
                if image_tensor is not None:
                    st.success("âœ… HÃ¬nh áº£nh Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ thÃ nh cÃ´ng!")
        
        with col2:
            st.markdown("#### ğŸ“ Nháº­p text imprint")
            text_imprint = st.text_input(
                "Text trÃªn viÃªn thuá»‘c:",
                placeholder="VÃ­ dá»¥: PILL123, MED500, RX10...",
                help="Nháº­p text Ä‘Æ°á»£c in trÃªn viÃªn thuá»‘c (náº¿u cÃ³)"
            )
            
            st.markdown("#### âš™ï¸ CÃ i Ä‘áº·t")
            show_features = st.checkbox("Hiá»ƒn thá»‹ phÃ¢n tÃ­ch features", value=True)
            confidence_threshold = st.slider(
                "NgÆ°á»¡ng Ä‘á»™ tin cáº­y",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                help="Chá»‰ hiá»ƒn thá»‹ káº¿t quáº£ cÃ³ Ä‘á»™ tin cáº­y trÃªn ngÆ°á»¡ng nÃ y"
            )
        
        # Prediction button
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸ¯ Nháº­n dáº¡ng viÃªn thuá»‘c", type="primary", use_container_width=True):
                if uploaded_file is not None and image_tensor is not None:
                    with st.spinner("ğŸ”„ Äang phÃ¢n tÃ­ch..."):
                        # Add progress bar
                        progress_bar = st.progress(0)
                        for i in range(100):
                            time.sleep(0.01)
                            progress_bar.progress(i + 1)
                        
                        # Make prediction
                        results = predict_pill(
                            model, image_tensor, text_imprint or "",
                            device, tokenizer, sample_data
                        )
                        
                        if results:
                            # Filter by confidence threshold
                            filtered_predictions = [
                                pred for pred in results["predictions"]
                                if pred["confidence"] >= confidence_threshold
                            ]
                            
                            if filtered_predictions:
                                results["predictions"] = filtered_predictions
                                display_prediction_results(results)
                                
                                if show_features:
                                    display_feature_analysis(results["features"])
                            else:
                                st.warning(f"âš ï¸ KhÃ´ng cÃ³ dá»± Ä‘oÃ¡n nÃ o Ä‘áº¡t ngÆ°á»¡ng tin cáº­y {confidence_threshold:.1%}")
                        else:
                            st.error("âŒ CÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh nháº­n dáº¡ng")
                else:
                    st.warning("âš ï¸ Vui lÃ²ng táº£i lÃªn hÃ¬nh áº£nh trÆ°á»›c khi nháº­n dáº¡ng")
    
    elif selected == "ğŸ“Š Thá»‘ng kÃª":
        st.markdown('<div class="section-header">ğŸ“Š Thá»‘ng kÃª Há»‡ thá»‘ng</div>', unsafe_allow_html=True)
        
        # Sample statistics
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ“ˆ PhÃ¢n bá»‘ dá»¯ liá»‡u máº«u")
            
            # Create sample distribution chart
            pill_types = [pill["name"] for pill in sample_data[:5]]
            confidences = [pill["confidence"] for pill in sample_data[:5]]
            
            fig = px.pie(
                values=confidences,
                names=pill_types,
                title="PhÃ¢n bá»‘ cÃ¡c loáº¡i thuá»‘c máº«u"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ¯ Hiá»‡u suáº¥t Model")
            
            # Mock performance metrics
            metrics_data = {
                "Metric": ["Accuracy", "Precision", "Recall", "F1-Score"],
                "Training": [0.95, 0.94, 0.93, 0.94],
                "Validation": [0.89, 0.88, 0.87, 0.88]
            }
            
            metrics_df = pd.DataFrame(metrics_data)
            fig = px.bar(
                metrics_df,
                x="Metric",
                y=["Training", "Validation"],
                title="Hiá»‡u suáº¥t Model trÃªn táº­p Train vÃ  Validation",
                barmode="group"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Training progress
        st.markdown("#### ğŸ“‰ QuÃ¡ trÃ¬nh Training")
        
        # Mock training data
        epochs = list(range(1, 51))
        train_loss = [0.8 * np.exp(-x/10) + 0.1 + np.random.normal(0, 0.02) for x in epochs]
        val_loss = [0.9 * np.exp(-x/12) + 0.15 + np.random.normal(0, 0.03) for x in epochs]
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=epochs, y=train_loss, mode='lines', name='Training Loss'))
        fig.add_trace(go.Scatter(x=epochs, y=val_loss, mode='lines', name='Validation Loss'))
        fig.update_layout(
            title="Loss theo Epoch",
            xaxis_title="Epoch",
            yaxis_title="Loss"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    elif selected == "â„¹ï¸ ThÃ´ng tin":
        st.markdown('<div class="section-header">â„¹ï¸ ThÃ´ng tin Há»‡ thá»‘ng</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng
            
            #### ğŸ¤– Multimodal Transformer
            - **Visual Encoder**: Vision Transformer (ViT) Ä‘á»ƒ xá»­ lÃ½ hÃ¬nh áº£nh
            - **Text Encoder**: BERT Ä‘á»ƒ xá»­ lÃ½ text imprint
            - **Cross-modal Attention**: Káº¿t há»£p thÃ´ng tin tá»« hai modality
            - **Fusion Layer**: Tá»•ng há»£p features cuá»‘i cÃ¹ng
            - **Classifier**: PhÃ¢n loáº¡i viÃªn thuá»‘c
            
            #### ğŸ’¾ Big Data Processing
            - **Apache Spark**: Xá»­ lÃ½ dá»¯ liá»‡u phÃ¢n tÃ¡n
            - **Rapids cuDF/cuML**: TÄƒng tá»‘c GPU
            - **Apache Parquet**: LÆ°u trá»¯ dá»¯ liá»‡u hiá»‡u quáº£
            - **Elasticsearch**: Index vÃ  tÃ¬m kiáº¿m text
            
            #### ğŸš€ Tech Stack
            - **Framework**: PyTorch, Transformers, Streamlit
            - **Data**: PySpark, Pandas, NumPy
            - **Visualization**: Plotly, Matplotlib
            - **Deployment**: Docker, Kubernetes
            """)
        
        with col2:
            st.markdown("""
            ### ğŸ”§ Cáº¥u hÃ¬nh Model
            """)
            
            if config:
                with st.expander("ğŸ“‹ Model Configuration"):
                    st.json(config["model"])
                
                with st.expander("ğŸ¯ Training Configuration"):
                    st.json(config["training"])
                
                with st.expander("ğŸ’¾ Data Configuration"):
                    st.json(config["data"])
        
        st.markdown("---")
        
        st.markdown("""
        ### ğŸ‘¥ NhÃ³m phÃ¡t triá»ƒn
        
        - **Há»c viÃªn**: [TÃªn sinh viÃªn]
        - **MÃ´n há»c**: Äá»“ Ã¡n Äáº¡i há»c
        - **TrÆ°á»ng**: [TÃªn trÆ°á»ng]
        - **NÄƒm**: 2025
        
        ### ğŸ“ LiÃªn há»‡
        
        - **Email**: [email@example.com]
        - **GitHub**: [github.com/username]
        - **Website**: [website.com]
        """)


if __name__ == "__main__":
    main()

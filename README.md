# ğŸ’Š Há»‡ thá»‘ng Nháº­n dáº¡ng ViÃªn Thuá»‘c Multimodal vá»›i Transformer

## ğŸ“ Tá»•ng quan

Dá»± Ã¡n nÃ y phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng nháº­n dáº¡ng viÃªn thuá»‘c tiÃªn tiáº¿n sá»­ dá»¥ng **Multimodal Transformer** Ä‘á»ƒ káº¿t há»£p thÃ´ng tin tá»« hÃ¬nh áº£nh viÃªn thuá»‘c vÃ  text imprint (chá»¯ in trÃªn viÃªn thuá»‘c). Há»‡ thá»‘ng Ã¡p dá»¥ng **Cross-modal Attention Mechanism** Ä‘á»ƒ há»c representation chung cho cáº£ visual vÃ  textual features, Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao trong viá»‡c phÃ¢n loáº¡i vÃ  nháº­n dáº¡ng viÃªn thuá»‘c.

## ğŸ¯ Má»¥c tiÃªu

- PhÃ¡t triá»ƒn há»‡ thá»‘ng multimodal fusion cho nháº­n dáº¡ng viÃªn thuá»‘c tá»« hÃ¬nh áº£nh vÃ  text
- Ãp dá»¥ng kiáº¿n trÃºc CLIP-like vá»›i Cross-modal attention mechanism
- Xá»­ lÃ½ dá»¯ liá»‡u lá»›n vá»›i Apache Spark vÃ  GPU acceleration
- Táº¡o giao diá»‡n ngÆ°á»i dÃ¹ng trá»±c quan vá»›i Streamlit

## ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng

### 1. Multimodal Transformer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Image Input   â”‚    â”‚   Text Input    â”‚
â”‚   (224x224x3)   â”‚    â”‚   (Imprint)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visual Encoder  â”‚    â”‚  Text Encoder   â”‚
â”‚     (ViT)       â”‚    â”‚     (BERT)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visual Features â”‚    â”‚ Text Features   â”‚
â”‚   (768 dims)    â”‚    â”‚   (768 dims)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Cross-modal     â”‚
           â”‚ Attention       â”‚
           â”‚ Fusion          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Classifier    â”‚
           â”‚ (Pill Classes)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. CÃ¡c thÃ nh pháº§n chÃ­nh

- **Visual Encoder**: Vision Transformer (ViT) hoáº·c CNN backbone
- **Text Encoder**: BERT-based transformer cho text imprint
- **Cross-modal Attention**: Mechanism káº¿t há»£p thÃ´ng tin tá»« hai modality
- **Fusion Layer**: Tá»•ng há»£p features tá»« visual vÃ  text
- **Classifier**: PhÃ¢n loáº¡i viÃªn thuá»‘c cuá»‘i cÃ¹ng

## ğŸš€ Tech Stack

### Core ML/DL Frameworks
- **PyTorch** 2.0+: Deep learning framework chÃ­nh
- **Transformers** 4.30+: BERT vÃ  ViT models
- **timm**: Vision models pretrained
- **torchvision**: Computer vision utilities

### Big Data & Distributed Computing
- **Apache Spark** 3.4+: Xá»­ lÃ½ dá»¯ liá»‡u phÃ¢n tÃ¡n
- **Rapids cuDF/cuML**: GPU acceleration cho pandas operations
- **Apache Parquet**: Columnar storage format
- **Elasticsearch**: Text indexing vÃ  search

### UI & Visualization
- **Streamlit** 1.25+: Web application framework
- **Plotly**: Interactive charts vÃ  graphs
- **streamlit-option-menu**: Enhanced navigation

### Data Processing
- **Pandas** 2.0+: Data manipulation
- **NumPy**: Numerical computing
- **Pillow**: Image processing
- **OpenCV**: Computer vision
- **Albumentations**: Data augmentation

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. Clone repository

```bash
git clone https://github.com/username/DoAnDLL.git
cd DoAnDLL
```

### 2. Táº¡o virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows
```

### 3. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 4. CÃ i Ä‘áº·t Rapids (tÃ¹y chá»n, cho GPU acceleration)

```bash
# Chá»‰ dÃ nh cho há»‡ thá»‘ng cÃ³ GPU NVIDIA
conda install -c rapidsai -c nvidia -c conda-forge cudf cuml
```

### 5. Setup Spark (tÃ¹y chá»n)

```bash
# Download vÃ  setup Apache Spark
wget https://downloads.apache.org/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz
tar -xzf spark-3.4.0-bin-hadoop3.tgz
export SPARK_HOME=/path/to/spark-3.4.0-bin-hadoop3
export PATH=$PATH:$SPARK_HOME/bin
```

## ğŸ® Sá»­ dá»¥ng

### 1. Cháº¡y á»©ng dá»¥ng Streamlit

```bash
streamlit run app.py
```

á»¨ng dá»¥ng sáº½ cháº¡y trÃªn `http://localhost:8501`

### 2. Training model

```bash
python src/training/trainer.py
```

### 3. Xá»­ lÃ½ dá»¯ liá»‡u vá»›i Spark

```python
from src.data.data_processing import SparkDataProcessor
import yaml

# Load config
with open("config/config.yaml", "r") as f:
    config = yaml.safe_load(f)

# Initialize processor
processor = SparkDataProcessor(config)

# Create sample dataset
processor.create_sample_dataset("data/raw/sample.parquet", 1000)

# Process data
df = processor.load_parquet_data("data/raw/sample.parquet")
processed_df = processor.preprocess_images(df)
processed_df = processor.clean_text_data(processed_df)

# Split and save
train_df, val_df, test_df = processor.create_train_val_test_split(processed_df)
processor.save_processed_data(train_df, val_df, test_df, "data/processed")
```

## ğŸ“Š Giao diá»‡n Streamlit

á»¨ng dá»¥ng Streamlit bao gá»“m cÃ¡c trang:

### ğŸ  Trang chá»§
- Giá»›i thiá»‡u há»‡ thá»‘ng
- Thá»‘ng kÃª tá»•ng quan
- HÆ°á»›ng dáº«n sá»­ dá»¥ng

### ğŸ” Nháº­n dáº¡ng
- Upload hÃ¬nh áº£nh viÃªn thuá»‘c
- Nháº­p text imprint
- Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n vá»›i Ä‘á»™ tin cáº­y
- PhÃ¢n tÃ­ch features multimodal

### ğŸ“Š Thá»‘ng kÃª
- Biá»ƒu Ä‘á»“ phÃ¢n bá»‘ dá»¯ liá»‡u
- Metrics hiá»‡u suáº¥t model
- QuÃ¡ trÃ¬nh training

### â„¹ï¸ ThÃ´ng tin
- Kiáº¿n trÃºc há»‡ thá»‘ng
- Cáº¥u hÃ¬nh model
- ThÃ´ng tin nhÃ³m phÃ¡t triá»ƒn

## ğŸ—‚ï¸ Cáº¥u trÃºc Dá»± Ã¡n

```
DoAnDLL/
â”œâ”€â”€ app.py                      # Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Documentation
â”œâ”€â”€ LICENSE                     # License file
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml            # Configuration file
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ multimodal_transformer.py  # Model architecture
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_processing.py         # Data processing vá»›i Spark
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py                 # Training pipeline
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ utils.py                   # Utility functions
â”‚       â””â”€â”€ metrics.py                 # Evaluation metrics
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Raw data
â”‚   â””â”€â”€ processed/             # Processed data
â”‚
â”œâ”€â”€ checkpoints/               # Model checkpoints
â”œâ”€â”€ logs/                     # Training logs
â””â”€â”€ notebooks/                # Jupyter notebooks
```

## âš™ï¸ Cáº¥u hÃ¬nh

File `config/config.yaml` chá»©a táº¥t cáº£ cáº¥u hÃ¬nh:

```yaml
model:
  visual_encoder:
    type: "vit"
    model_name: "vit_base_patch16_224"
  text_encoder:
    type: "bert"
    model_name: "bert-base-uncased"
  fusion:
    type: "cross_attention"
    num_attention_heads: 8

training:
  batch_size: 32
  learning_rate: 1e-4
  num_epochs: 100

data:
  image_size: 224
  spark:
    app_name: "PillRecognitionETL"
    master: "local[*]"
```

## ğŸ§ª Dataset

Há»‡ thá»‘ng há»— trá»£ xá»­ lÃ½ dataset viÃªn thuá»‘c vá»›i:

- **HÃ¬nh áº£nh**: Format JPG/PNG, resize vá» 224x224
- **Text imprint**: Text Ä‘Æ°á»£c in trÃªn viÃªn thuá»‘c
- **Labels**: PhÃ¢n loáº¡i viÃªn thuá»‘c
- **Metadata**: ThÃ´ng tin bá»• sung (liá»u lÆ°á»£ng, nhÃ  sáº£n xuáº¥t, etc.)

### Äá»‹nh dáº¡ng dá»¯ liá»‡u

```json
{
  "image_id": "img_000001",
  "image_path": "path/to/image.jpg",
  "text_imprint": "PILL123",
  "pill_class": "Acetaminophen 500mg",
  "class_id": 0,
  "metadata": {
    "dosage": "500mg",
    "manufacturer": "Company A"
  }
}
```

## ğŸ‹ï¸ Training

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u

```bash
python src/data/data_processing.py
```

### 2. Training model

```bash
python src/training/trainer.py --config config/config.yaml
```

### 3. Theo dÃµi training vá»›i Weights & Biases

```bash
# Setup wandb
wandb login
wandb init
```

## ğŸ“ˆ Evaluation Metrics

Há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ model báº±ng cÃ¡c metrics:

- **Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Precision/Recall/F1**: Cho tá»«ng class
- **Top-k Accuracy**: Accuracy trong top-k predictions
- **Confusion Matrix**: Ma tráº­n nháº§m láº«n
- **Cross-modal Similarity**: Äá»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a visual vÃ  text features

## ğŸš€ Deployment

### Docker

```dockerfile
FROM python:3.8-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8501

CMD ["streamlit", "run", "app.py"]
```

### Build vÃ  cháº¡y

```bash
docker build -t pill-recognition .
docker run -p 8501:8501 pill-recognition
```

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

## ğŸ“„ License

Dá»± Ã¡n Ä‘Æ°á»£c phÃ¢n phá»‘i dÆ°á»›i MIT License. Xem `LICENSE` Ä‘á»ƒ biáº¿t thÃªm thÃ´ng tin.

## ğŸ™ Acknowledgments

- [Transformers](https://huggingface.co/transformers/) - BERT vÃ  ViT models
- [timm](https://github.com/rwightman/pytorch-image-models) - Vision models
- [Apache Spark](https://spark.apache.org/) - Big data processing
- [Rapids](https://rapids.ai/) - GPU acceleration
- [Streamlit](https://streamlit.io/) - Web application framework

## ğŸ“ LiÃªn há»‡

- **TÃ¡c giáº£**: [TÃªn sinh viÃªn]
- **Email**: [email@example.com]
- **GitHub**: [https://github.com/username](https://github.com/username)
- **LinkedIn**: [https://linkedin.com/in/username](https://linkedin.com/in/username)

---

â­ Náº¿u dá»± Ã¡n nÃ y há»¯u Ã­ch, hÃ£y cho chÃºng tÃ´i má»™t star!
#!/bin/bash

# Test Dataset and Port Management
# Smart Pill Recognition System

echo "ðŸ§ª Testing Dataset and Port Management"
echo "====================================="
echo ""

# Color codes
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_test() {
    echo -e "${BLUE}ðŸ§ª${NC} Testing: $1"
}

print_pass() {
    echo -e "${GREEN}âœ…${NC} PASS: $1"
}

print_fail() {
    echo -e "${RED}âŒ${NC} FAIL: $1"
}

print_info() {
    echo -e "${YELLOW}â„¹ï¸${NC}  INFO: $1"
}

# Test 1: Dataset Structure
print_test "CURE Dataset Structure"
if [ -d "Dataset_BigData/CURE_dataset" ]; then
    print_pass "Dataset directory found"
    
    # Check subdirectories
    if [ -d "Dataset_BigData/CURE_dataset/CURE_dataset_train_cut_bounding_box" ]; then
        train_classes=$(find Dataset_BigData/CURE_dataset/CURE_dataset_train_cut_bounding_box -mindepth 1 -maxdepth 1 -type d | wc -l)
        print_pass "Training data found - $train_classes classes"
    else
        print_fail "Training data not found"
    fi
    
    if [ -d "Dataset_BigData/CURE_dataset/CURE_dataset_validation_cut_bounding_box" ]; then
        val_classes=$(find Dataset_BigData/CURE_dataset/CURE_dataset_validation_cut_bounding_box -mindepth 1 -maxdepth 1 -type d | wc -l)
        print_pass "Validation data found - $val_classes classes"
    else
        print_fail "Validation data not found"
    fi
    
    if [ -d "Dataset_BigData/CURE_dataset/CURE_dataset_test" ]; then
        test_images=$(find Dataset_BigData/CURE_dataset/CURE_dataset_test -name "*.jpg" | wc -l)
        print_pass "Test data found - $test_images images"
    else
        print_fail "Test data not found"
    fi
else
    print_fail "Dataset directory not found at Dataset_BigData/CURE_dataset"
    print_info "Please ensure CURE dataset is properly extracted to Dataset_BigData/"
fi

echo ""

# Test 2: Port Management
print_test "Port Management"

# Test Python port manager
python3 -c "
import sys
sys.path.append('src')
try:
    from utils.port_manager import PortManager, get_streamlit_port
    pm = PortManager()
    
    # Test port availability
    print('Testing port availability...')
    for port in [8088, 8051, 8501, 8502, 8503]:
        available = pm.is_port_available(port)
        status = 'Available' if available else 'In use'
        print(f'  Port {port}: {status}')
    
    # Test finding available port
    available_port = get_streamlit_port(8501)
    print(f'Recommended Streamlit port: {available_port}')
    
    # Test server constraints
    constraints = pm.check_server_constraints()
    print(f'Available ports in range: {len(constraints[\"available_ports\"])}')
    
    if constraints['recommendations']:
        print('Recommendations:')
        for rec in constraints['recommendations']:
            print(f'  - {rec}')
    
    print('âœ… Port management test completed')
except ImportError as e:
    print(f'âŒ Import error: {e}')
except Exception as e:
    print(f'âŒ Error: {e}')
" 2>/dev/null

if [ $? -eq 0 ]; then
    print_pass "Port management module working"
else
    print_fail "Port management module has issues"
fi

echo ""

# Test 3: Dataset Loading
print_test "Dataset Loading"

python3 -c "
import sys
sys.path.append('src')
try:
    from data.cure_dataset import CUREDataset, analyze_cure_dataset
    import os
    
    dataset_path = 'Dataset_BigData/CURE_dataset'
    
    if os.path.exists(dataset_path):
        print('Loading dataset...')
        
        # Test train dataset
        try:
            train_dataset = CUREDataset(dataset_path, split='train')
            print(f'âœ… Train dataset: {len(train_dataset)} samples, {len(train_dataset.classes)} classes')
        except Exception as e:
            print(f'âŒ Train dataset error: {e}')
        
        # Test validation dataset
        try:
            val_dataset = CUREDataset(dataset_path, split='validation')
            print(f'âœ… Validation dataset: {len(val_dataset)} samples, {len(val_dataset.classes)} classes')
        except Exception as e:
            print(f'âŒ Validation dataset error: {e}')
        
        # Test loading a sample
        try:
            sample = train_dataset[0]
            print(f'âœ… Sample loading: image shape {sample[\"image\"].shape}, class {sample[\"class_name\"]}')
        except Exception as e:
            print(f'âŒ Sample loading error: {e}')
        
    else:
        print('âŒ Dataset path not found')
        
except ImportError as e:
    print(f'âŒ Import error: {e}')
except Exception as e:
    print(f'âŒ Error: {e}')
" 2>/dev/null

if [ $? -eq 0 ]; then
    print_pass "Dataset loading test completed"
else
    print_fail "Dataset loading has issues"
fi

echo ""

# Test 4: Dependencies
print_test "Python Dependencies"

missing_deps=()

python3 -c "import torch; print(f'PyTorch: {torch.__version__}')" 2>/dev/null || missing_deps+=("torch")
python3 -c "import torchvision; print(f'TorchVision: {torchvision.__version__}')" 2>/dev/null || missing_deps+=("torchvision")
python3 -c "import PIL; print(f'Pillow: {PIL.__version__}')" 2>/dev/null || missing_deps+=("Pillow")
python3 -c "import pandas; print(f'Pandas: {pandas.__version__}')" 2>/dev/null || missing_deps+=("pandas")
python3 -c "import streamlit; print(f'Streamlit: {streamlit.__version__}')" 2>/dev/null || missing_deps+=("streamlit")

if [ ${#missing_deps[@]} -eq 0 ]; then
    print_pass "All dependencies available"
else
    print_fail "Missing dependencies: ${missing_deps[*]}"
    print_info "Run 'pip install -r requirements.txt' to install missing packages"
fi

echo ""

# Test 5: GPU and CUDA (if available)
print_test "GPU and CUDA"

if command -v nvidia-smi > /dev/null 2>&1; then
    GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)
    print_pass "GPU detected: $GPU_NAME"
    
    if command -v nvcc > /dev/null 2>&1; then
        CUDA_VERSION=$(nvcc --version | grep -o 'release [0-9.]*' | cut -d' ' -f2)
        print_pass "CUDA available: $CUDA_VERSION"
    else
        print_fail "CUDA not found"
    fi
    
    # Test PyTorch CUDA
    python3 -c "
import torch
if torch.cuda.is_available():
    print(f'âœ… PyTorch CUDA: {torch.version.cuda}')
    print(f'âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')
else:
    print('âŒ PyTorch CUDA not available')
" 2>/dev/null
else
    print_info "No GPU detected - will use CPU mode"
fi

echo ""

# Summary
echo "ðŸ“Š Test Summary"
echo "==============="

# Quick diagnostic
if [ -d "Dataset_BigData/CURE_dataset" ] && python3 -c "import sys; sys.path.append('src'); from utils.port_manager import PortManager" 2>/dev/null; then
    print_pass "System ready for dataset integration"
    echo ""
    echo "ðŸš€ Ready to run:"
    echo "  ./run                 # Start with dataset integration"
    echo "  ./run --dataset       # Setup dataset only"
    echo "  ./run --port-check    # Check port availability"
else
    print_fail "System needs configuration"
    echo ""
    echo "ðŸ”§ Next steps:"
    echo "  1. Ensure CURE dataset is in Dataset_BigData/"
    echo "  2. Run: pip install -r requirements.txt"
    echo "  3. Run: ./setup (if not already done)"
fi

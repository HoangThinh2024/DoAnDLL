#!/bin/bash

# Smart Pill Recognition - Test Suite
# Comprehensive testing for Ubuntu 22.04 + CUDA 12.8 + Quadro 6000

echo "üß™ Smart Pill Recognition - Test Suite"
echo "======================================"

# Function to show usage
show_help() {
    echo "Usage: ./test [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --system     Test system requirements"
    echo "  --gpu        Test GPU functionality"
    echo "  --cuda       Test CUDA installation"
    echo "  --model      Test model loading"
    echo "  --app        Test application"
    echo "  --full       Run all tests"
    echo "  --help       Show this help"
    echo ""
    echo "Examples:"
    echo "  ./test              # Quick system check"
    echo "  ./test --gpu        # Test GPU only"
    echo "  ./test --full       # Complete test suite"
}

# Function to test system
test_system() {
    echo "üñ•Ô∏è Testing System Requirements..."
    
    echo "üìã System Information:"
    echo "OS: $(lsb_release -d | cut -f2)"
    echo "Kernel: $(uname -r)"
    echo "Memory: $(free -h | grep '^Mem:' | awk '{print $2}')"
    echo "Storage: $(df -h / | tail -1 | awk '{print $4}') free"
    
    # Check Python
    if python3 --version > /dev/null 2>&1; then
        echo "‚úÖ Python: $(python3 --version)"
    else
        echo "‚ùå Python: Not found"
        return 1
    fi
    
    # Check essential tools
    for tool in git curl wget; do
        if command -v $tool > /dev/null 2>&1; then
            echo "‚úÖ $tool: Available"
        else
            echo "‚ùå $tool: Not found"
        fi
    done
}

# Function to test GPU
test_gpu() {
    echo "üéÆ Testing GPU..."
    
    if nvidia-smi > /dev/null 2>&1; then
        echo "‚úÖ NVIDIA Driver: Available"
        nvidia-smi --query-gpu=name,memory.total,temperature.gpu --format=csv,noheader
        
        # Test GPU with Python
        python3 -c "
import torch
if torch.cuda.is_available():
    print('‚úÖ PyTorch CUDA: Available')
    print(f'GPU Count: {torch.cuda.device_count()}')
    for i in range(torch.cuda.device_count()):
        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
    
    # Test tensor operations
    try:
        x = torch.randn(1000, 1000).cuda()
        y = torch.randn(1000, 1000).cuda()
        z = torch.mm(x, y)
        print('‚úÖ GPU Operations: Working')
    except Exception as e:
        print(f'‚ùå GPU Operations: Failed - {e}')
else:
    print('‚ùå PyTorch CUDA: Not available')
"
    else
        echo "‚ùå NVIDIA Driver: Not found"
        return 1
    fi
}

# Function to test CUDA
test_cuda() {
    echo "üî• Testing CUDA 12.8..."
    
    if nvcc --version > /dev/null 2>&1; then
        CUDA_VERSION=$(nvcc --version | grep -oP 'release \K[0-9.]+')
        echo "‚úÖ CUDA Version: $CUDA_VERSION"
        
        if [[ $CUDA_VERSION == 12.8* ]]; then
            echo "‚úÖ CUDA 12.8: Perfect match"
        else
            echo "‚ö†Ô∏è  CUDA Version: Expected 12.8, found $CUDA_VERSION"
        fi
        
        # Test cuDNN
        python3 -c "
import torch
if torch.backends.cudnn.is_available():
    print(f'‚úÖ cuDNN: Version {torch.backends.cudnn.version()}')
else:
    print('‚ùå cuDNN: Not available')
"
    else
        echo "‚ùå CUDA: Not found in PATH"
        return 1
    fi
}

# Function to test model
test_model() {
    echo "ü§ñ Testing Model Loading..."
    
    if [ -f "src/models/multimodal_transformer.py" ]; then
        python3 -c "
import sys
sys.path.append('src')

try:
    from models.multimodal_transformer import MultimodalPillTransformer
    import yaml
    
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    model = MultimodalPillTransformer(config['model'])
    total_params = sum(p.numel() for p in model.parameters())
    print(f'‚úÖ Model: Loaded successfully')
    print(f'Parameters: {total_params:,}')
    
    import torch
    if torch.cuda.is_available():
        model = model.cuda()
        print('‚úÖ GPU Transfer: Success')
        
except Exception as e:
    print(f'‚ùå Model Loading: Failed - {e}')
"
    else
        echo "‚ùå Model files not found"
        return 1
    fi
}

# Function to test application
test_app() {
    echo "üåê Testing Application..."
    
    # Check if app.py exists
    if [ -f "app.py" ]; then
        echo "‚úÖ app.py: Found"
        
        # Test import
        python3 -c "
try:
    import streamlit as st
    print('‚úÖ Streamlit: Available')
    
    # Test basic imports from app
    import sys
    sys.path.append('.')
    
    import torch
    import numpy as np
    from PIL import Image
    print('‚úÖ Dependencies: Available')
    
except ImportError as e:
    print(f'‚ùå Import Error: {e}')
"
    else
        echo "‚ùå app.py: Not found"
        return 1
    fi
}

# Function to run performance benchmark
test_performance() {
    echo "‚ö° Performance Benchmark..."
    
    python3 -c "
import torch
import time

if torch.cuda.is_available():
    device = torch.device('cuda')
    
    # Warm up
    x = torch.randn(1000, 1000, device=device)
    y = torch.randn(1000, 1000, device=device)
    _ = torch.mm(x, y)
    
    # Benchmark
    torch.cuda.synchronize()
    start_time = time.time()
    
    for _ in range(100):
        z = torch.mm(x, y)
    
    torch.cuda.synchronize()
    end_time = time.time()
    
    avg_time = (end_time - start_time) / 100 * 1000
    print(f'Matrix Multiplication: {avg_time:.2f} ms avg')
    
    # Memory info
    allocated = torch.cuda.memory_allocated() / (1024**3)
    cached = torch.cuda.memory_reserved() / (1024**3)
    total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    print(f'GPU Memory: {allocated:.1f}GB used / {total:.1f}GB total')
    
else:
    print('‚ùå CUDA not available for benchmarking')
"
}

# Parse command line arguments
case "$1" in
    --system)
        test_system
        ;;
    --gpu)
        test_gpu
        ;;
    --cuda)
        test_cuda
        ;;
    --model)
        test_model
        ;;
    --app)
        test_app
        ;;
    --performance)
        test_performance
        ;;
    --full)
        echo "üöÄ Running Complete Test Suite..."
        echo ""
        test_system && echo "" && \
        test_gpu && echo "" && \
        test_cuda && echo "" && \
        test_model && echo "" && \
        test_app && echo "" && \
        test_performance
        echo ""
        echo "‚úÖ All tests completed!"
        ;;
    --help)
        show_help
        ;;
    "")
        # Default: quick system check
        echo "üîç Quick System Check..."
        echo ""
        test_system
        echo ""
        test_gpu
        echo ""
        echo "üí° Run './test --full' for complete testing"
        echo "üí° Run './test --help' for more options"
        ;;
    *)
        echo "‚ùå Unknown option: $1"
        show_help
        exit 1
        ;;
esac

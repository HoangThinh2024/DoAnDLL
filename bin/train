#!/bin/bash

# Multimodal Pill Recognition Training Launcher
# Optimized for Ubuntu 22.04 + NVIDIA Quadro 6000 + CUDA 12.8

set -e

echo "ğŸš€ CURE Dataset Multimodal Training Launcher"
echo "============================================="

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if script is run from project root
if [ ! -f "pyproject.toml" ]; then
    echo -e "${RED}âŒ Error: Please run this script from the project root directory${NC}"
    exit 1
fi

# Check if dataset exists
DATASET_PATH="Dataset_BigData/CURE_dataset/CURE_dataset_train_cut_bounding_box"
if [ ! -d "$DATASET_PATH" ]; then
    echo -e "${RED}âŒ Error: CURE dataset not found at $DATASET_PATH${NC}"
    echo "Please ensure the CURE dataset is properly extracted in Dataset_BigData/"
    exit 1
fi

# Check CUDA availability
echo -e "${BLUE}ğŸ” Checking CUDA availability...${NC}"
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else \"None\"}')" || {
    echo -e "${RED}âŒ Error: Python/PyTorch not properly installed${NC}"
    echo "Please run: ./setup"
    exit 1
}

# Check dependencies
echo -e "${BLUE}ğŸ” Checking dependencies...${NC}"
python3 -c "from paddleocr import PaddleOCR; from transformers import BertTokenizer; print('âœ… All dependencies available')" || {
    echo -e "${YELLOW}âš ï¸  Some dependencies missing. Installing...${NC}"
    ./setup
}

# Create training directory if needed
mkdir -p logs

# Set default training parameters
EPOCHS=30
BATCH_SIZE=16
LEARNING_RATE=1e-4
VALIDATION_SPLIT=0.2
PATIENCE=5
SEED=42

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --epochs)
            EPOCHS="$2"
            shift 2
            ;;
        --batch-size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --learning-rate)
            LEARNING_RATE="$2"
            shift 2
            ;;
        --validation-split)
            VALIDATION_SPLIT="$2"
            shift 2
            ;;
        --patience)
            PATIENCE="$2"
            shift 2
            ;;
        --seed)
            SEED="$2"
            shift 2
            ;;
        --quick)
            echo -e "${YELLOW}ğŸš€ Quick training mode (for testing)${NC}"
            EPOCHS=3
            BATCH_SIZE=8
            shift
            ;;
        --help|-h)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --epochs EPOCHS            Number of training epochs (default: 30)"
            echo "  --batch-size SIZE          Batch size (default: 16)"
            echo "  --learning-rate RATE       Learning rate (default: 1e-4)"
            echo "  --validation-split RATIO   Validation split ratio (default: 0.2)"
            echo "  --patience PATIENCE        Early stopping patience (default: 5)"
            echo "  --seed SEED                Random seed (default: 42)"
            echo "  --quick                    Quick training mode for testing (3 epochs)"
            echo "  --help, -h                 Show this help message"
            echo ""
            echo "Examples:"
            echo "  ./train                    # Train with default parameters"
            echo "  ./train --quick            # Quick test training"
            echo "  ./train --epochs 50        # Train for 50 epochs"
            echo "  ./train --batch-size 32    # Use batch size 32"
            exit 0
            ;;
        *)
            echo -e "${RED}âŒ Unknown option: $1${NC}"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# Display training configuration
echo -e "${GREEN}ğŸ“‹ Training Configuration:${NC}"
echo "  Dataset: $DATASET_PATH"
echo "  Epochs: $EPOCHS"
echo "  Batch Size: $BATCH_SIZE"
echo "  Learning Rate: $LEARNING_RATE"
echo "  Validation Split: $VALIDATION_SPLIT"
echo "  Early Stopping Patience: $PATIENCE"
echo "  Random Seed: $SEED"
echo ""

# Ask for confirmation unless in quick mode
if [[ "$*" != *"--quick"* ]]; then
    read -p "ğŸ¤” Continue with training? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo -e "${YELLOW}Training cancelled.${NC}"
        exit 0
    fi
fi

# Create log file with timestamp
TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
LOG_FILE="logs/training_${TIMESTAMP}.log"

echo -e "${GREEN}ğŸ‹ï¸  Starting multimodal training...${NC}"
echo "ğŸ“„ Training log: $LOG_FILE"
echo ""

# Run training with logging
python3 train_cure_model.py \
    --dataset-path "$DATASET_PATH" \
    --epochs "$EPOCHS" \
    --batch-size "$BATCH_SIZE" \
    --learning-rate "$LEARNING_RATE" \
    --validation-split "$VALIDATION_SPLIT" \
    --patience "$PATIENCE" \
    --seed "$SEED" \
    2>&1 | tee "$LOG_FILE"

# Check if training was successful
if [ ${PIPESTATUS[0]} -eq 0 ]; then
    echo ""
    echo -e "${GREEN}ğŸ‰ Training completed successfully!${NC}"
    echo -e "${BLUE}ğŸ“Š Check the training_results_* directory for outputs${NC}"
    echo -e "${BLUE}ğŸ“„ Training log saved to: $LOG_FILE${NC}"
    echo ""
    echo -e "${YELLOW}Next steps:${NC}"
    echo "1. Review training plots and metrics"
    echo "2. Test the model: python Dataset_BigData/CURE_dataset/recognition.py"
    echo "3. Run the app: ./run"
    echo "4. Deploy: ./deploy"
else
    echo ""
    echo -e "${RED}âŒ Training failed. Check the log for details: $LOG_FILE${NC}"
    exit 1
fi

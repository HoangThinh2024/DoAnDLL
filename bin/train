#!/bin/bash

# Multimodal Pill Recognition Training Launcher
# Optimized for Ubuntu 22.04 + NVIDIA Quadro 6000 + CUDA 12.8

set -e

echo "üöÄ CURE Dataset Multimodal Training Launcher"
echo "============================================="

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if script is run from project root
if [ ! -f "pyproject.toml" ]; then
    echo -e "${RED}‚ùå Error: Please run this script from the project root directory${NC}"
    exit 1
fi

# Check if dataset exists
DATASET_PATH="Dataset_BigData/CURE_dataset/CURE_dataset_train_cut_bounding_box"
if [ ! -d "$DATASET_PATH" ]; then
    echo -e "${RED}‚ùå Error: CURE dataset not found at $DATASET_PATH${NC}"
    echo "Please ensure the CURE dataset is properly extracted in Dataset_BigData/"
    exit 1
fi

# Check CUDA availability
echo -e "${BLUE}üîç Checking CUDA availability...${NC}"
python3 -c "
try:
    import torch
    print(f'CUDA available: {torch.cuda.is_available()}')
    print(f'GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else \"None\"}')
except ImportError:
    print('PyTorch not installed - will run in simulation mode')
" || {
    echo -e "${YELLOW}‚ö†Ô∏è  PyTorch not installed. Running in simulation mode...${NC}"
    echo -e "${BLUE}‚ÑπÔ∏è  For full training functionality, install PyTorch: pip install torch${NC}"
}

# Check dependencies
echo -e "${BLUE}üîç Checking dependencies...${NC}"
python3 -c "
try:
    from paddleocr import PaddleOCR
    from transformers import BertTokenizer
    print('‚úÖ All dependencies available')
except ImportError as e:
    print(f'‚ö†Ô∏è  Some dependencies missing: {e}')
    print('Will proceed with available functionality...')
"

# Create training directory if needed
mkdir -p logs

# Set default training parameters
EPOCHS=30
BATCH_SIZE=16
LEARNING_RATE=1e-4
VALIDATION_SPLIT=0.2
PATIENCE=5
SEED=42

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --epochs)
            EPOCHS="$2"
            shift 2
            ;;
        --batch-size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --learning-rate)
            LEARNING_RATE="$2"
            shift 2
            ;;
        --validation-split)
            VALIDATION_SPLIT="$2"
            shift 2
            ;;
        --patience)
            PATIENCE="$2"
            shift 2
            ;;
        --seed)
            SEED="$2"
            shift 2
            ;;
        --quick)
            echo -e "${YELLOW}üöÄ Quick training mode (for testing)${NC}"
            EPOCHS=3
            BATCH_SIZE=8
            shift
            ;;
        --help|-h)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --epochs EPOCHS            Number of training epochs (default: 30)"
            echo "  --batch-size SIZE          Batch size (default: 16)"
            echo "  --learning-rate RATE       Learning rate (default: 1e-4)"
            echo "  --validation-split RATIO   Validation split ratio (default: 0.2)"
            echo "  --patience PATIENCE        Early stopping patience (default: 5)"
            echo "  --seed SEED                Random seed (default: 42)"
            echo "  --quick                    Quick training mode for testing (3 epochs)"
            echo "  --help, -h                 Show this help message"
            echo ""
            echo "Examples:"
            echo "  ./train                    # Train with default parameters"
            echo "  ./train --quick            # Quick test training"
            echo "  ./train --epochs 50        # Train for 50 epochs"
            echo "  ./train --batch-size 32    # Use batch size 32"
            exit 0
            ;;
        *)
            echo -e "${RED}‚ùå Unknown option: $1${NC}"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# Display training configuration
echo -e "${GREEN}üìã Training Configuration:${NC}"
echo "  Dataset: $DATASET_PATH"
echo "  Epochs: $EPOCHS"
echo "  Batch Size: $BATCH_SIZE"
echo "  Learning Rate: $LEARNING_RATE"
echo "  Validation Split: $VALIDATION_SPLIT"
echo "  Early Stopping Patience: $PATIENCE"
echo "  Random Seed: $SEED"
echo ""

# Ask for confirmation unless in quick mode
if [[ "$*" != *"--quick"* ]]; then
    read -p "ü§î Continue with training? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo -e "${YELLOW}Training cancelled.${NC}"
        exit 0
    fi
fi

# Create log file with timestamp
TIMESTAMP=$(date '+%Y%m%d_%H%M%S')
LOG_FILE="logs/training_${TIMESTAMP}.log"

echo -e "${GREEN}üèãÔ∏è  Starting multimodal training...${NC}"
echo "üìÑ Training log: $LOG_FILE"
echo ""

# Run training with logging
# Use the correct training script path, with fallback to simulation
PYTORCH_AVAILABLE=false
python3 -c "import torch" 2>/dev/null && PYTORCH_AVAILABLE=true

if [ "$PYTORCH_AVAILABLE" = "true" ] && [ -f "train_multi_method.py" ]; then
    echo "üîÑ Using train_multi_method.py for training..."
    python3 train_multi_method.py \
        --dataset-path "$DATASET_PATH" \
        --epochs "$EPOCHS" \
        --batch-size "$BATCH_SIZE" \
        --learning-rate "$LEARNING_RATE" \
        --validation-split "$VALIDATION_SPLIT" \
        --patience "$PATIENCE" \
        --seed "$SEED" \
        2>&1 | tee "$LOG_FILE"
elif [ "$PYTORCH_AVAILABLE" = "true" ] && [ -f "legacy/train_cure_model.py" ]; then
    echo "üîÑ Using legacy/train_cure_model.py for training..."
    python3 legacy/train_cure_model.py \
        --dataset-path "$DATASET_PATH" \
        --epochs "$EPOCHS" \
        --batch-size "$BATCH_SIZE" \
        --learning-rate "$LEARNING_RATE" \
        --validation-split "$VALIDATION_SPLIT" \
        --patience "$PATIENCE" \
        --seed "$SEED" \
        2>&1 | tee "$LOG_FILE"
elif [ -f "training_simulation.py" ]; then
    echo "üîÑ Using training_simulation.py for demonstration..."
    echo -e "${YELLOW}‚ÑπÔ∏è  Running training simulation (PyTorch not available)${NC}"
    python3 training_simulation.py \
        --dataset-path "$DATASET_PATH" \
        --epochs "$EPOCHS" \
        --batch-size "$BATCH_SIZE" \
        --learning-rate "$LEARNING_RATE" \
        --validation-split "$VALIDATION_SPLIT" \
        --patience "$PATIENCE" \
        --seed "$SEED" \
        2>&1 | tee "$LOG_FILE"
else
    echo -e "${RED}‚ùå Error: No training script found${NC}"
    echo "Available scripts:"
    echo "  - train_multi_method.py (requires PyTorch)"
    echo "  - legacy/train_cure_model.py (requires PyTorch)"
    echo "  - training_simulation.py (demo mode)"
    exit 1
fi

# Check if training was successful
if [ ${PIPESTATUS[0]} -eq 0 ]; then
    echo ""
    echo -e "${GREEN}üéâ Training completed successfully!${NC}"
    echo -e "${BLUE}üìä Check the training_results_* directory for outputs${NC}"
    echo -e "${BLUE}üìÑ Training log saved to: $LOG_FILE${NC}"
    echo ""
    echo -e "${YELLOW}Next steps:${NC}"
    echo "1. Review training plots and metrics"
    echo "2. Test the model: python Dataset_BigData/CURE_dataset/recognition.py"
    echo "3. Run the app: ./run"
    echo "4. Deploy: ./deploy"
else
    echo ""
    echo -e "${RED}‚ùå Training failed. Check the log for details: $LOG_FILE${NC}"
    exit 1
fi

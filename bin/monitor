#!/bin/bash

# GPU Monitoring script for Nvidia Quadro 6000
# Monitor GPU usage, temperature, and memory during model training/inference

echo "🎮 Nvidia Quadro 6000 Monitoring Dashboard"
echo "=========================================="

# Function to get GPU info
get_gpu_info() {
    echo "📊 GPU Information:"
    if command -v nvidia-smi &> /dev/null; then
        nvidia-smi --query-gpu=name,driver_version,memory.total,memory.used,memory.free,temperature.gpu,utilization.gpu,utilization.memory --format=csv,noheader,nounits
    else
        echo "⚠️  nvidia-smi not found. GPU monitoring not available in this environment."
        echo "System info:"
        echo "CPU: $(nproc) cores"
        echo "Memory: $(free -h | awk '/^Mem:/ {print $2}')"
        echo "OS: $(uname -s) $(uname -r)"
    fi
}

# Function to monitor continuously
monitor_continuous() {
    if ! command -v nvidia-smi &> /dev/null; then
        echo "⚠️  nvidia-smi not found. Starting CPU/Memory monitoring instead..."
        echo "🔄 Starting continuous monitoring (Press Ctrl+C to stop)"
        while true; do
            clear
            echo "💻 System Monitoring Dashboard (No GPU)"
            echo "Time: $(date)"
            echo "=========================================="
            
            echo "📊 CPU Usage:"
            top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1 | awk '{printf "CPU Usage: %.1f%%\n", $1}'
            
            echo ""
            echo "💾 Memory Usage:"
            free -h | awk '/^Mem:/ {printf "Used: %s / %s (%.1f%%)\n", $3, $2, ($3/$2)*100}'
            
            echo ""
            echo "🔥 System Load:"
            uptime | awk -F'load average:' '{print "Load Average:" $2}'
            
            echo ""
            echo "💽 Disk Usage:"
            df -h | awk '$NF=="/" {printf "Disk Usage: %s / %s (%s)\n", $3, $2, $5}'
            
            sleep 5
        done
        return
    fi
    
    echo "🔄 Starting continuous monitoring (Press Ctrl+C to stop)"
    while true; do
        clear
        echo "🎮 Nvidia Quadro 6000 Real-time Monitoring"
        echo "Time: $(date)"
        echo "=========================================="
        
        # GPU Status
        echo "📈 GPU Status:"
        nvidia-smi --query-gpu=utilization.gpu,utilization.memory,temperature.gpu,power.draw --format=csv,noheader,nounits | \
        awk -F', ' '{printf "GPU Utilization: %s%%\nMemory Utilization: %s%%\nTemperature: %s°C\nPower Draw: %sW\n", $1, $2, $3, $4}'
        
        echo ""
        echo "💾 Memory Usage:"
        nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits | \
        awk -F', ' '{printf "Used: %s MB / %s MB (%.1f%%)\n", $1, $2, ($1/$2)*100}'
        
        echo ""
        echo "🔥 Thermal Status:"
        temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
        if [ $temp -lt 60 ]; then
            echo "Temperature: ${temp}°C ✅ (Normal)"
        elif [ $temp -lt 80 ]; then
            echo "Temperature: ${temp}°C ⚠️  (Warm)"
        else
            echo "Temperature: ${temp}°C 🔥 (Hot - Check cooling!)"
        fi
        
        echo ""
        echo "⚡ Power Status:"
        power=$(nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits | cut -d'.' -f1)
        max_power=$(nvidia-smi --query-gpu=power.max_limit --format=csv,noheader,nounits | cut -d'.' -f1)
        power_percent=$(echo "scale=1; $power * 100 / $max_power" | bc)
        echo "Power Draw: ${power}W / ${max_power}W (${power_percent}%)"
        
        echo ""
        echo "🐳 Docker Container GPU Usage:"
        docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" | grep pill-recognition 2>/dev/null || echo "No pill-recognition containers running"
        
        sleep 5
    done
}

# Function to log GPU stats
log_stats() {
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    log_file="logs/gpu_monitoring_$(date +%Y%m%d).log"
    
    mkdir -p logs
    
    echo "[$timestamp] GPU Stats:" >> $log_file
    nvidia-smi --query-gpu=utilization.gpu,utilization.memory,temperature.gpu,power.draw,memory.used,memory.total --format=csv,noheader,nounits >> $log_file
    echo "Logged to $log_file"
}

# Function to check GPU health
check_health() {
    echo "🏥 System Health Check:"
    
    if ! command -v nvidia-smi &> /dev/null; then
        echo "⚠️  nvidia-smi not found - checking system health instead"
        
        # Check CPU temperature (if available)
        if command -v sensors &> /dev/null; then
            temp=$(sensors | grep "Core 0" | awk '{print $3}' | tr -d '+°C' 2>/dev/null || echo "N/A")
            if [ "$temp" != "N/A" ] && [ $temp -gt 80 ]; then
                echo "❌ CPU temperature too high: ${temp}°C (>80°C)"
            elif [ "$temp" != "N/A" ]; then
                echo "✅ CPU temperature OK: ${temp}°C"
            else
                echo "ℹ️  CPU temperature monitoring not available"
            fi
        else
            echo "ℹ️  Temperature monitoring not available (install lm-sensors)"
        fi
        
        # Check memory usage
        memory_percent=$(free | awk '/^Mem:/ {printf "%.1f", ($3/$2)*100}')
        if (( $(echo "$memory_percent > 90" | bc -l) )); then
            echo "❌ Memory usage too high: ${memory_percent}%"
        else
            echo "✅ Memory usage OK: ${memory_percent}%"
        fi
        
        # Check disk space
        disk_percent=$(df / | awk 'NR==2 {print $5}' | tr -d '%')
        if [ $disk_percent -gt 90 ]; then
            echo "❌ Disk usage too high: ${disk_percent}%"
        else
            echo "✅ Disk usage OK: ${disk_percent}%"
        fi
        
        echo "✅ System is accessible (no GPU)"
        return
    fi
    
    # Check temperature
    temp=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)
    if [ $temp -gt 85 ]; then
        echo "❌ Temperature too high: ${temp}°C (>85°C)"
    else
        echo "✅ Temperature OK: ${temp}°C"
    fi
    
    # Check memory usage
    memory_used=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits)
    memory_total=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits)
    memory_percent=$(echo "scale=1; $memory_used * 100 / $memory_total" | bc)
    
    if (( $(echo "$memory_percent > 95" | bc -l) )); then
        echo "❌ Memory usage too high: ${memory_percent}%"
    else
        echo "✅ Memory usage OK: ${memory_percent}%"
    fi
    
    # Check if GPU is accessible
    if nvidia-smi > /dev/null 2>&1; then
        echo "✅ GPU is accessible"
    else
        echo "❌ GPU not accessible"
    fi
}

# Function to optimize GPU settings
optimize_gpu() {
    if ! command -v nvidia-smi &> /dev/null; then
        echo "⚠️  nvidia-smi not found - GPU optimization not available"
        echo "🔧 Applying general system optimizations instead..."
        
        # CPU governor optimization (if available)
        if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor ]; then
            echo "Setting CPU governor to performance mode..."
            echo "performance" | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor > /dev/null 2>&1 || echo "Need sudo privileges for CPU optimization"
        fi
        
        # Adjust swappiness for better performance
        echo "Optimizing memory settings..."
        echo 10 | sudo tee /proc/sys/vm/swappiness > /dev/null 2>&1 || echo "Need sudo privileges for memory optimization"
        
        echo "✅ System optimizations applied (limited without GPU)"
        return
    fi
    
    echo "🔧 Applying Quadro 6000 optimizations..."
    
    # Set persistence mode
    sudo nvidia-smi -pm 1
    
    # Set max performance mode
    sudo nvidia-smi -ac 6251,1911
    
    # Set power limit to maximum
    sudo nvidia-smi -pl 300
    
    echo "✅ GPU optimizations applied"
}

# Main menu
case "$1" in
    "monitor")
        monitor_continuous
        ;;
    "log")
        log_stats
        ;;
    "health")
        check_health
        ;;
    "optimize")
        optimize_gpu
        ;;
    "info")
        get_gpu_info
        ;;
    *)
        echo "Usage: $0 {monitor|log|health|optimize|info}"
        echo ""
        echo "Commands:"
        echo "  monitor  - Start continuous monitoring"
        echo "  log      - Log current stats to file"
        echo "  health   - Check GPU health status"
        echo "  optimize - Apply Quadro 6000 optimizations"
        echo "  info     - Show GPU information"
        exit 1
        ;;
esac
